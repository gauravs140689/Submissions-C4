{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Assignment 2: Advanced RAG Techniques\n",
        "## Day 6 Session 2 - Advanced RAG Fundamentals\n",
        "\n",
        "**OBJECTIVE:** Implement advanced RAG techniques including postprocessors, response synthesizers, and structured outputs.\n",
        "\n",
        "**LEARNING GOALS:**\n",
        "- Understand and implement node postprocessors for filtering and reranking\n",
        "- Learn different response synthesis strategies (TreeSummarize, Refine)\n",
        "- Create structured outputs using Pydantic models\n",
        "- Build advanced retrieval pipelines with multiple processing stages\n",
        "\n",
        "**DATASET:** Use the same data folder as Assignment 1 (`Day_6/session_2/data/`)\n",
        "\n",
        "**PREREQUISITES:** Complete Assignment 1 first\n",
        "\n",
        "**INSTRUCTIONS:**\n",
        "1. Complete each function by replacing the TODO comments with actual implementation\n",
        "2. Run each cell after completing the function to test it\n",
        "3. The answers can be found in the `03_advanced_rag_techniques.ipynb` notebook\n",
        "4. Each technique builds on the previous one\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Advanced RAG libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries for advanced RAG\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Any\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Core LlamaIndex components\n",
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext, Settings\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "\n",
        "# Vector store\n",
        "from llama_index.vector_stores.lancedb import LanceDBVectorStore\n",
        "\n",
        "# Embeddings and LLM\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.llms.openrouter import OpenRouter\n",
        "\n",
        "# Advanced RAG components (we'll use these in the assignments)\n",
        "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
        "from llama_index.core.response_synthesizers import TreeSummarize, Refine, CompactAndRefine\n",
        "from llama_index.core.output_parsers import PydanticOutputParser\n",
        "\n",
        "print(\"âœ… Advanced RAG libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… OPENROUTER_API_KEY found - full advanced RAG functionality available\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 199/199 [00:00<00:00, 1885.33it/s, Materializing param=pooler.dense.weight]                               \n",
            "\u001b[1mBertModel LOAD REPORT\u001b[0m from: BAAI/bge-small-en-v1.5\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Advanced RAG settings configured\n",
            "   - Chunk size: 512 (optimized for precision)\n",
            "   - Using local embeddings for cost efficiency\n",
            "   - OpenRouter LLM ready for response synthesis\n"
          ]
        }
      ],
      "source": [
        "# Configure Advanced RAG Settings (Using OpenRouter)\n",
        "def setup_advanced_rag_settings():\n",
        "    \"\"\"\n",
        "    Configure LlamaIndex with optimized settings for advanced RAG.\n",
        "    Uses local embeddings and OpenRouter for LLM operations.\n",
        "    \"\"\"\n",
        "    # Load environment variables from .env file\n",
        "    load_dotenv()\n",
        "    \n",
        "    # Check for OpenRouter API key\n",
        "    api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "    if not api_key:\n",
        "        print(\"âš ï¸  OPENROUTER_API_KEY not found - LLM operations will be limited\")\n",
        "        print(\"   You can still complete postprocessor and retrieval exercises\")\n",
        "    else:\n",
        "        print(\"âœ… OPENROUTER_API_KEY found - full advanced RAG functionality available\")\n",
        "        \n",
        "        # Configure OpenRouter LLM\n",
        "        Settings.llm = OpenRouter(\n",
        "            api_key=api_key,\n",
        "            model=\"gpt-4o\",\n",
        "            temperature=0.1  # Lower temperature for more consistent responses\n",
        "        )\n",
        "    \n",
        "    # Configure local embeddings (no API key required)\n",
        "    Settings.embed_model = HuggingFaceEmbedding(\n",
        "        model_name=\"BAAI/bge-small-en-v1.5\",\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "    \n",
        "    # Advanced RAG configuration\n",
        "    Settings.chunk_size = 512  # Smaller chunks for better precision\n",
        "    Settings.chunk_overlap = 50\n",
        "    \n",
        "    print(\"âœ… Advanced RAG settings configured\")\n",
        "    print(\"   - Chunk size: 512 (optimized for precision)\")\n",
        "    print(\"   - Using local embeddings for cost efficiency\")\n",
        "    print(\"   - OpenRouter LLM ready for response synthesis\")\n",
        "\n",
        "# Setup the configuration\n",
        "setup_advanced_rag_settings()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Table documents doesn't exist yet. Please add some data to create it.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“ Setting up basic index for advanced RAG...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/chandru/python-sandbox/.venv/lib/python3.12/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/Users/chandru/python-sandbox/.venv/lib/python3.12/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/Users/chandru/python-sandbox/.venv/lib/python3.12/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "Parsing nodes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42/42 [00:00<00:00, 131.94it/s]\n",
            "Generating embeddings: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94/94 [00:02<00:00, 33.04it/s]\n",
            "2026-02-08 02:27:04,285 - INFO - Create new table documents adding data.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Basic index created with 42 documents\n",
            "   Ready for advanced RAG techniques!\n",
            "ðŸš€ Ready to implement advanced RAG techniques!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[90m[\u001b[0m2026-02-08T07:27:04Z \u001b[33mWARN \u001b[0m lance::dataset::write::insert\u001b[90m]\u001b[0m No existing dataset at /Users/chandru/python-sandbox/Outskill_AI_Acc_Assignments/RAG_Atlas_session_3/assignments/advanced_rag_vectordb/documents.lance, it will be created\n"
          ]
        }
      ],
      "source": [
        "# Setup: Create index from Assignment 1 (reuse the basic functionality)\n",
        "def setup_basic_index(data_folder: str = \"../data\", force_rebuild: bool = False):\n",
        "    \"\"\"\n",
        "    Create a basic vector index that we'll enhance with advanced techniques.\n",
        "    This reuses the concepts from Assignment 1.\n",
        "    \"\"\"\n",
        "    # Create vector store\n",
        "    vector_store = LanceDBVectorStore(\n",
        "        uri=\"./advanced_rag_vectordb\",\n",
        "        table_name=\"documents\"\n",
        "    )\n",
        "    \n",
        "    # Load documents\n",
        "    if not Path(data_folder).exists():\n",
        "        print(f\"âŒ Data folder not found: {data_folder}\")\n",
        "        return None\n",
        "        \n",
        "    reader = SimpleDirectoryReader(input_dir=data_folder, recursive=True)\n",
        "    documents = reader.load_data()\n",
        "    \n",
        "    # Create storage context and index\n",
        "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "    index = VectorStoreIndex.from_documents(\n",
        "        documents, \n",
        "        storage_context=storage_context,\n",
        "        show_progress=True\n",
        "    )\n",
        "    \n",
        "    print(f\"âœ… Basic index created with {len(documents)} documents\")\n",
        "    print(\"   Ready for advanced RAG techniques!\")\n",
        "    return index\n",
        "\n",
        "# Create the basic index\n",
        "print(\"ðŸ“ Setting up basic index for advanced RAG...\")\n",
        "index = setup_basic_index()\n",
        "\n",
        "if index:\n",
        "    print(\"ðŸš€ Ready to implement advanced RAG techniques!\")\n",
        "else:\n",
        "    print(\"âŒ Failed to create index - check data folder path\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Node Postprocessors - Similarity Filtering\n",
        "\n",
        "**Concept:** Postprocessors refine retrieval results after the initial vector search. The `SimilarityPostprocessor` filters out chunks that fall below a relevance threshold.\n",
        "\n",
        "**Why it matters:** Raw vector search often returns some irrelevant results. Filtering improves precision and response quality.\n",
        "\n",
        "Complete the function below to create a query engine with similarity filtering.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-08 02:34:45,865 - INFO - query_type :, vector\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created query engine with similarity cutoff 0.3\n",
            "âœ… Query engine with similarity filtering created\n",
            "\n",
            "ðŸ” Testing query: 'What are the benefits of AI agents?'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-08 02:34:47,031 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 02:34:48,366 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 02:34:50,605 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“ Response: AI agents offer significant benefits, including the ability to achieve complex objectives through sophisticated reasoning, planning, and tool utilization. They can autonomously engage with complex environments, make informed decisions, and assist humans in a wide range of tasks. These agents work iteratively, allowing for task breakdown, continuous improvement, and clear role allocation, which boosts their performance. Additionally, multi-agent systems can distribute tasks across multiple agents and provide feedback from various viewpoints, enhancing the overall efficiency and success of task execution.\n",
            "   (Function is now fully implemented)\n"
          ]
        }
      ],
      "source": [
        "def create_query_engine_with_similarity_filter(index, similarity_cutoff: float = 0.3, top_k: int = 10):\n",
        "    \"\"\"\n",
        "    Create a query engine that filters results based on similarity scores.\n",
        "    \n",
        "    TODO: Complete this function to create a query engine with similarity postprocessing.\n",
        "    HINT: Use index.as_query_engine() with node_postprocessors parameter containing SimilarityPostprocessor\n",
        "    \n",
        "    Args:\n",
        "        index: Vector index to query\n",
        "        similarity_cutoff: Minimum similarity score (0.0 to 1.0)\n",
        "        top_k: Number of initial results to retrieve before filtering\n",
        "        \n",
        "    Returns:\n",
        "        Query engine with similarity filtering\n",
        "    \"\"\"\n",
        "    # Create similarity postprocessor with the cutoff threshold\n",
        "    similarity_processor = SimilarityPostprocessor(similarity_cutoff=similarity_cutoff)\n",
        "    \n",
        "    # Create query engine with similarity filtering\n",
        "    query_engine = index.as_query_engine(similarity_top_k=top_k,node_postprocessors=[similarity_processor])\n",
        "    \n",
        "    # return query_engine\n",
        "    \n",
        "    # PLACEHOLDER - Replace with actual implementation\n",
        "    print(f\"Created query engine with similarity cutoff {similarity_cutoff}\")\n",
        "    return query_engine\n",
        "\n",
        "# Test the function\n",
        "if index:\n",
        "    filtered_engine = create_query_engine_with_similarity_filter(index, similarity_cutoff=0.3)\n",
        "    \n",
        "    if filtered_engine:\n",
        "        print(\"âœ… Query engine with similarity filtering created\")\n",
        "        \n",
        "        # Test query\n",
        "        test_query = \"What are the benefits of AI agents?\"\n",
        "        print(f\"\\nðŸ” Testing query: '{test_query}'\")\n",
        "        \n",
        "        # Uncomment when implemented:\n",
        "        response = filtered_engine.query(test_query)\n",
        "        print(f\"ðŸ“ Response: {response}\")\n",
        "        print(\"   (Function is now fully implemented)\")\n",
        "    else:\n",
        "        print(\"âŒ Failed to create filtered query engine\")\n",
        "else:\n",
        "    print(\"âŒ No index available - run previous cells first\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Response Synthesizers - TreeSummarize\n",
        "\n",
        "**Concept:** Response synthesizers control how retrieved information becomes final answers. `TreeSummarize` builds responses hierarchically, ideal for complex analytical questions.\n",
        "\n",
        "**Why it matters:** Different synthesis strategies work better for different query types. TreeSummarize excels at comprehensive analysis and long-form responses.\n",
        "\n",
        "Complete the function below to create a query engine with TreeSummarize response synthesis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-08 02:51:16,000 - INFO - query_type :, vector\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created query engine with TreeSummarize synthesis\n",
            "âœ… Query engine with TreeSummarize created\n",
            "\n",
            "ðŸ” Testing analytical query: 'Compare the advantages and disadvantages of different AI agent frameworks'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-08 02:51:16,555 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“ TreeSummarize Response:\n",
            "Different AI agent frameworks offer various advantages and disadvantages based on their design and intended use cases.\n",
            "\n",
            "**Advantages:**\n",
            "\n",
            "1. **Autonomous Agents:**\n",
            "   - **AutoGPT**: Known for its high complexity and ability to execute autonomous tasks, making it suitable for scenarios requiring minimal human intervention.\n",
            "   - **BabyAGI**: Offers a simplified approach, which can be beneficial for those looking for an easier entry point into autonomous AI.\n",
            "\n",
            "2. **Tool-Using Agents:**\n",
            "   - **LangChain**: Provides a comprehensive framework for LLM applications, with a moderate learning curve, making it versatile for general applications.\n",
            "   - **LlamaIndex**: Specializes in document understanding and retrieval-augmented generation (RAG), with a low complexity and easy learning curve, ideal for document Q&A tasks.\n",
            "\n",
            "3. **Multi-Agent Systems:**\n",
            "   - **CrewAI**: Facilitates team collaboration with a medium complexity and easy learning curve, making it effective for tasks requiring collaborative efforts.\n",
            "   - **MetaGPT**: Focuses on multi-agent software development, which can enhance accuracy in complex tasks through collaborative problem-solving.\n",
            "\n",
            "**Disadvantages:**\n",
            "\n",
            "1. **Autonomous Agents:**\n",
            "   - **AutoGPT**: Has a steep learning curve and high\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import get_response_synthesizer\n",
        "\n",
        "def create_query_engine_with_tree_summarize(index, top_k: int = 5):\n",
        "    \"\"\"\n",
        "    Create a query engine that uses TreeSummarize for comprehensive responses.\n",
        "    \n",
        "    TODO: Complete this function to create a query engine with TreeSummarize synthesis.\n",
        "    HINT: Create a TreeSummarize instance, then use index.as_query_engine() with response_synthesizer parameter\n",
        "    \n",
        "    Args:\n",
        "        index: Vector index to query\n",
        "        top_k: Number of results to retrieve\n",
        "        \n",
        "    Returns:\n",
        "        Query engine with TreeSummarize synthesis\n",
        "    \"\"\"\n",
        "    # Create TreeSummarize response synthesizer\n",
        "    tree_synthesizer = get_response_synthesizer(response_mode=\"tree_summarize\", use_async=True)\n",
        "    \n",
        "    # Create query engine with the synthesizer\n",
        "    query_engine = index.as_query_engine(\n",
        "        similarity_top_k=top_k,\n",
        "        response_synthesizer=tree_synthesizer\n",
        "    )\n",
        "    \n",
        "    # PLACEHOLDER - Replace with actual implementation\n",
        "    print(f\"Created query engine with TreeSummarize synthesis\")\n",
        "    return query_engine\n",
        "\n",
        "# Test the function\n",
        "if index:\n",
        "    tree_engine = create_query_engine_with_tree_summarize(index)\n",
        "    \n",
        "    if tree_engine:\n",
        "        print(\"âœ… Query engine with TreeSummarize created\")\n",
        "        \n",
        "        # Test with a complex analytical query\n",
        "        analytical_query = \"Compare the advantages and disadvantages of different AI agent frameworks\"\n",
        "        print(f\"\\nðŸ” Testing analytical query: '{analytical_query}'\")\n",
        "        \n",
        "        # Uncomment when implemented:\n",
        "        response = tree_engine.query(analytical_query)\n",
        "        print(f\"ðŸ“ TreeSummarize Response:\\n{response}\")\n",
        "    else:\n",
        "        print(\"âŒ Failed to create TreeSummarize query engine\")\n",
        "else:\n",
        "    print(\"âŒ No index available - run previous cells first\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Structured Outputs with Pydantic Models\n",
        "\n",
        "**Concept:** Structured outputs ensure predictable, parseable responses using Pydantic models. This is essential for API endpoints and data pipelines.\n",
        "\n",
        "**Why it matters:** Instead of free-text responses, you get type-safe, validated data structures that applications can reliably process.\n",
        "\n",
        "Complete the function below to create a structured output system for extracting research paper information.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-08 03:11:02,146 - INFO - query_type :, vector\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created structured output program with ResearchPaperInfo\n",
            "âœ… Structured output program created\n",
            "\n",
            "ðŸ” Testing structured query: 'Tell me about AI agents and their capabilities'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-08 03:11:02,557 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“Š Structured Response:\n",
            "title='The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey' key_points=['AI agents are capable of achieving complex goals through enhanced reasoning, planning, and tool execution.', 'Single-agent patterns perform well with defined personas, tools, and iterative feedback.', 'Multi-agent systems benefit from clear leadership, dynamic team composition, and intelligent communication filtering.', 'Current challenges include the lack of standardized benchmarks for evaluating AI agents and mitigating biases from underlying language models.', 'Future improvements are needed in real-world applicability and reliability of AI agents.'] applications=['Complex task execution requiring reasoning and planning', 'Dynamic team collaboration for problem-solving', 'Enhanced tool execution in AI-driven systems'] summary='This survey paper explores advancements in AI agent architectures, focusing on their capabilities in reasoning, planning, and tool execution. It highlights the strengths of single and multi-agent systems, identifies current challenges, and suggests areas for future research and development.'\n",
            "\n",
            "ðŸ’¡ Expected output format:\n",
            "   - title: The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey\n",
            "   - key_points: ['AI agents are capable of achieving complex goals through enhanced reasoning, planning, and tool execution.', 'Single-agent patterns perform well with defined personas, tools, and iterative feedback.', 'Multi-agent systems benefit from clear leadership, dynamic team composition, and intelligent communication filtering.', 'Current challenges include the lack of standardized benchmarks for evaluating AI agents and mitigating biases from underlying language models.', 'Future improvements are needed in real-world applicability and reliability of AI agents.']\n",
            "   - applications: ['Complex task execution requiring reasoning and planning', 'Dynamic team collaboration for problem-solving', 'Enhanced tool execution in AI-driven systems']\n",
            "   - summary: This survey paper explores advancements in AI agent architectures, focusing on their capabilities in reasoning, planning, and tool execution. It highlights the strengths of single and multi-agent systems, identifies current challenges, and suggests areas for future research and development.\n"
          ]
        }
      ],
      "source": [
        "# First, define the Pydantic models for structured outputs  \n",
        "class ResearchPaperInfo(BaseModel):\n",
        "    \"\"\"Structured information about a research paper or AI concept.\"\"\"\n",
        "    title: str = Field(description=\"The main title or concept name\")\n",
        "    key_points: List[str] = Field(description=\"3-5 main points or findings\")\n",
        "    applications: List[str] = Field(description=\"Practical applications or use cases\")\n",
        "    summary: str = Field(description=\"Brief 2-3 sentence summary\")\n",
        "\n",
        "# Import the missing component\n",
        "from llama_index.core.program import LLMTextCompletionProgram\n",
        "from llama_index.core.prompts import PromptTemplate\n",
        "\n",
        "def create_structured_output_program(output_model: BaseModel = ResearchPaperInfo):\n",
        "    \"\"\"\n",
        "    Create a structured output program using Pydantic models.\n",
        "    \n",
        "    TODO: Complete this function to create a structured output program.\n",
        "    HINT: Use LLMTextCompletionProgram.from_defaults() with PydanticOutputParser and a prompt template\n",
        "    \n",
        "    Args:\n",
        "        output_model: Pydantic model class for structured output\n",
        "        \n",
        "    Returns:\n",
        "        LLMTextCompletionProgram that returns structured data\n",
        "    \"\"\"\n",
        "    # 1. Create a prompt template that expects 'context' and 'query'\n",
        "    # The program will use the Pydantic schema to instruct the LLM on the output format\n",
        "    prompt_template_str = (\n",
        "        \"Context information is below.\\n\"\n",
        "        \"---------------------\\n\"\n",
        "        \"{context}\\n\"\n",
        "        \"---------------------\\n\"\n",
        "        \"Given the context information, please answer the following query in a structured format: {query}\\n\"\n",
        "    )\n",
        "    prompt = PromptTemplate(prompt_template_str)\n",
        "\n",
        "    # 2. Create the structured output program\n",
        "    # This automatically creates the PydanticOutputParser internally \n",
        "    # when you pass the output_cls\n",
        "    program = LLMTextCompletionProgram.from_defaults(\n",
        "        output_cls=output_model,\n",
        "        prompt=prompt,\n",
        "        llm=Settings.llm,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    # return program\n",
        "    \n",
        "    # PLACEHOLDER - Replace with actual implementation\n",
        "    print(f\"Created structured output program with {output_model.__name__}\")\n",
        "    return program\n",
        "\n",
        "# Test the function\n",
        "if index:\n",
        "    structured_program = create_structured_output_program(ResearchPaperInfo)\n",
        "    \n",
        "    if structured_program:\n",
        "        print(\"âœ… Structured output program created\")\n",
        "        \n",
        "        # Test with retrieval and structured extraction\n",
        "        structure_query = \"Tell me about AI agents and their capabilities\"\n",
        "        print(f\"\\nðŸ” Testing structured query: '{structure_query}'\")\n",
        "        \n",
        "        # Get context for structured extraction (Uncomment when implemented)\n",
        "        retriever = VectorIndexRetriever(index=index, similarity_top_k=3)\n",
        "        nodes = retriever.retrieve(structure_query)\n",
        "        context = \"\\n\".join([node.text for node in nodes])\n",
        "        \n",
        "        # Uncomment when implemented:\n",
        "        response = structured_program(context=context, query=structure_query)\n",
        "        print(f\"ðŸ“Š Structured Response:\\n{response}\")\n",
        "        #print(\"   (Complete the function above to get structured JSON output)\")\n",
        "        \n",
        "        print(\"\\nðŸ’¡ Expected output format:\")\n",
        "        print(f\"   - title: {response.title}\")\n",
        "        print(f\"   - key_points: {response.key_points}\")\n",
        "        print(f\"   - applications: {response.applications}\") \n",
        "        print(f\"   - summary: {response.summary}\")\n",
        "    else:\n",
        "        print(\"âŒ Failed to create structured output program\")\n",
        "else:\n",
        "    print(\"âŒ No index available - run previous cells first\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Advanced Pipeline - Combining All Techniques\n",
        "\n",
        "**Concept:** Combine multiple advanced techniques into a single powerful query engine: similarity filtering + response synthesis + structured output.\n",
        "\n",
        "**Why it matters:** Production RAG systems often need multiple techniques working together for optimal results.\n",
        "\n",
        "Complete the function below to create a comprehensive advanced RAG pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-08 03:16:11,790 - INFO - query_type :, vector\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created advanced RAG pipeline with similarity_cutoff=0.3, top_k=10\n",
            "âœ… Advanced RAG pipeline created successfully!\n",
            "   ðŸ”§ Similarity filtering: âœ…\n",
            "   ðŸŒ³ TreeSummarize synthesis: âœ…\n",
            "\n",
            "ðŸ” Testing complex query: 'Analyze the current state and future potential of AI agent technologies'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-08 03:16:12,484 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 03:16:12,526 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 03:16:15,432 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸš€ Advanced RAG Response:\n",
            "AI agent technologies are currently in a promising state, with significant advancements in their ability to perform complex tasks such as reasoning, planning, and tool execution. Both single and multi-agent architectures have shown strong performance, especially when incorporating elements like defined personas, iterative feedback, and dynamic team structures. However, challenges remain, including the need for comprehensive benchmarks, real-world applicability, and bias mitigation.\n",
            "\n",
            "In the financial services industry, AI agents are transforming operations by significantly boosting productivity and improving risk management. They have demonstrated productivity increases of 50-80% in financial data tasks and show promise in areas like algorithmic trading and fraud detection. Despite these advancements, challenges such as workforce upskilling, risk alignment, and regulatory compliance need to be addressed for successful deployment.\n",
            "\n",
            "Looking to the future, AI agent technologies have substantial potential, particularly in fields like finance, where they can revolutionize trading, investment analysis, and risk management. The integration of large language models and sophisticated frameworks is expected to enhance automation and intelligence. Future research will likely focus on overcoming scalability, regulatory compliance, and integration challenges. Collaboration between academia, industry, and open-source communities will be crucial to fully realize the potential of these technologies. Additionally, developing standardized architectures, robust testing protocols, and hybrid human-AI workflows will be\n",
            "\n",
            "ðŸŽ¯ This should provide:\n",
            "   - Filtered relevant results only\n",
            "   - Comprehensive analytical response\n",
            "   - Combined postprocessing and synthesis\n"
          ]
        }
      ],
      "source": [
        "def create_advanced_rag_pipeline(index, similarity_cutoff: float = 0.3, top_k: int = 10):\n",
        "    \"\"\"\n",
        "    Create a comprehensive advanced RAG pipeline combining multiple techniques.\n",
        "    \n",
        "    TODO: Complete this function to create the ultimate advanced RAG query engine.\n",
        "    HINT: Combine SimilarityPostprocessor + TreeSummarize using index.as_query_engine()\n",
        "    \n",
        "    Args:\n",
        "        index: Vector index to query\n",
        "        similarity_cutoff: Minimum similarity score for filtering\n",
        "        top_k: Number of initial results to retrieve\n",
        "        \n",
        "    Returns:\n",
        "        Advanced query engine with filtering and synthesis combined\n",
        "    \"\"\"\n",
        "    # TODO: Create similarity postprocessor\n",
        "    similarity_processor = SimilarityPostprocessor(similarity_cutoff=similarity_cutoff)\n",
        "    \n",
        "    # TODO: Create TreeSummarize for comprehensive responses\n",
        "    tree_synthesizer = get_response_synthesizer(response_mode=\"tree_summarize\", use_async=True)\n",
        "    \n",
        "    # TODO: Create the comprehensive query engine combining both techniques\n",
        "    advanced_engine = index.as_query_engine(\n",
        "        similarity_top_k=top_k,\n",
        "        node_postprocessors=[similarity_processor],\n",
        "        response_synthesizer=tree_synthesizer\n",
        "    )\n",
        "    \n",
        "    # return advanced_engine\n",
        "    \n",
        "    # PLACEHOLDER - Replace with actual implementation\n",
        "    print(f\"Created advanced RAG pipeline with similarity_cutoff={similarity_cutoff}, top_k={top_k}\")\n",
        "    return advanced_engine\n",
        "\n",
        "# Test the comprehensive pipeline\n",
        "if index:\n",
        "    advanced_pipeline = create_advanced_rag_pipeline(index)\n",
        "    \n",
        "    if advanced_pipeline:\n",
        "        print(\"âœ… Advanced RAG pipeline created successfully!\")\n",
        "        print(\"   ðŸ”§ Similarity filtering: âœ…\")\n",
        "        print(\"   ðŸŒ³ TreeSummarize synthesis: âœ…\")\n",
        "        \n",
        "        # Test with complex query\n",
        "        complex_query = \"Analyze the current state and future potential of AI agent technologies\"\n",
        "        print(f\"\\nðŸ” Testing complex query: '{complex_query}'\")\n",
        "        \n",
        "        # Uncomment when implemented:\n",
        "        response = advanced_pipeline.query(complex_query)\n",
        "        print(f\"ðŸš€ Advanced RAG Response:\\n{response}\")\n",
        "        #print(\"   (Complete the function above to test the full pipeline)\")\n",
        "        \n",
        "        print(\"\\nðŸŽ¯ This should provide:\")\n",
        "        print(\"   - Filtered relevant results only\")\n",
        "        print(\"   - Comprehensive analytical response\")\n",
        "        print(\"   - Combined postprocessing and synthesis\")\n",
        "    else:\n",
        "        print(\"âŒ Failed to create advanced RAG pipeline\")\n",
        "else:\n",
        "    print(\"âŒ No index available - run previous cells first\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Final Test - Compare Basic vs Advanced RAG\n",
        "\n",
        "Once you've completed all the functions above, run this cell to compare basic RAG with your advanced techniques.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-08 03:18:18,381 - INFO - query_type :, vector\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸš€ Advanced RAG Techniques Assignment - Final Test\n",
            "============================================================\n",
            "\n",
            "ðŸ“Š Component Status:\n",
            "   âœ… Basic Index\n",
            "   âœ… Similarity Filter\n",
            "   âœ… TreeSummarize\n",
            "   âœ… Structured Output\n",
            "   âœ… Advanced Pipeline\n",
            "\n",
            "ðŸ” Creating basic query engine for comparison...\n",
            "\n",
            "============================================================\n",
            "ðŸ†š COMPARISON: Basic vs Advanced RAG\n",
            "============================================================\n",
            "\n",
            "ðŸ“‹ Test Query 1: 'What are the key capabilities of AI agents?'\n",
            "--------------------------------------------------\n",
            "ðŸ”¹ Basic RAG:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-08 03:18:19,202 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 03:18:20,088 - INFO - query_type :, vector\n",
            "2026-02-08 03:18:20,111 - INFO - Retrying request to /chat/completions in 0.447635 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Response: AI agents are designed to extend language model capabilities to solve real-world challenges. Their key capabilities include reasoning, planning, and the ability to call tools that interact with an ext...\n",
            "   (Standard vector search + simple response)\n",
            "\n",
            "ðŸ”¸ Advanced RAG:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-08 03:18:20,729 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 03:18:21,109 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 03:18:22,984 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 03:18:23,840 - INFO - query_type :, vector\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Response: AI agents have several key capabilities that enable them to solve complex problems effectively. These include reasoning, which allows them to make decisions and understand complex environments; planning, which involves creating and refining strategies to achieve goals; and tool calling, which enables interaction with external data sources. They can operate autonomously, either as single entities or within multi-agent systems, where they can collaborate and communicate to enhance task performance. Additionally, AI agents can model complex behaviors, particularly in economic and financial contexts, and are capable of sophisticated communication and coordination. They also integrate data, provide explainability, and manage risks effectively.\n",
            "   (Filtered + TreeSummarize + Structured output)\n",
            "\n",
            "ðŸ“‹ Test Query 2: 'How do you evaluate agent performance metrics?'\n",
            "--------------------------------------------------\n",
            "ðŸ”¹ Basic RAG:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-08 03:18:24,255 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 03:18:25,350 - INFO - query_type :, vector\n",
            "2026-02-08 03:18:25,372 - INFO - Retrying request to /chat/completions in 0.396265 seconds\n",
            "2026-02-08 03:18:25,374 - INFO - Retrying request to /chat/completions in 0.438888 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Response: Agent performance metrics are evaluated using both objective and subjective measures. Objective metrics include success rate, output similarity to human responses, and overall efficiency. Subjective m...\n",
            "   (Standard vector search + simple response)\n",
            "\n",
            "ðŸ”¸ Advanced RAG:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-08 03:18:26,294 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 03:18:26,300 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 03:18:28,053 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 03:18:29,616 - INFO - query_type :, vector\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Response: Agent performance metrics are evaluated using a variety of key performance indicators and benchmarks. These include measuring accuracy, which assesses the correctness of predictions and decisions, and efficiency, which looks at the speed and resource consumption in task completion. Robustness is another important metric, evaluating the system's ability to handle noisy or incomplete data and unexpected events. Specific benchmarks may focus on particular environments or tasks to determine how well agents can generalize to new situations. Additionally, human evaluation is often required for more nuanced or subjective measures, such as tool use efficiency and planning robustness. In multi-agent systems, performance is also assessed based on inter-agent communication effectiveness, collaborative plan execution, and task completion speed, with metrics like communication cost and time to task completion being commonly used.\n",
            "   (Filtered + TreeSummarize + Structured output)\n",
            "\n",
            "ðŸ“‹ Test Query 3: 'Explain the benefits and challenges of multimodal AI systems'\n",
            "--------------------------------------------------\n",
            "ðŸ”¹ Basic RAG:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-08 03:18:29,985 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 03:18:33,006 - INFO - query_type :, vector\n",
            "2026-02-08 03:18:33,027 - INFO - Retrying request to /chat/completions in 0.477573 seconds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Response: Multimodal AI systems offer several benefits, including the ability to process and integrate information from multiple sources such as text, images, and audio, which can lead to more comprehensive und...\n",
            "   (Standard vector search + simple response)\n",
            "\n",
            "ðŸ”¸ Advanced RAG:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-08 03:18:33,809 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 03:18:34,171 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 03:18:36,805 - INFO - HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Response: Multimodal AI systems offer several benefits, such as enhanced understanding and decision-making capabilities by integrating information from various data types like text, images, and audio. This integration allows for more comprehensive analysis and insights, improving performance in complex tasks such as image captioning and sentiment analysis. Additionally, these systems can provide more natural and intuitive user interactions by leveraging the strengths of different modalities.\n",
            "\n",
            "However, there are challenges associated with these systems. One major challenge is the complexity involved in effectively combining and synchronizing different data modalities, which often requires sophisticated algorithms and increased computational resources. Ensuring robustness and reliability across various modalities is also a concern, as errors in one modality can impact overall performance. Furthermore, developing and training these systems can be resource-intensive, requiring large datasets that cover all relevant modalities and standardized frameworks to ensure consistency across applications.\n",
            "   (Filtered + TreeSummarize + Structured output)\n",
            "\n",
            "============================================================\n",
            "ðŸŽ¯ Assignment Status:\n",
            "   Completed: 5/5 components\n",
            "\n",
            "ðŸŽ‰ Congratulations! You've mastered Advanced RAG Techniques!\n",
            "   âœ… Node postprocessors for result filtering\n",
            "   âœ… Response synthesizers for better answers\n",
            "   âœ… Structured outputs for reliable data\n",
            "   âœ… Advanced pipelines combining all techniques\n",
            "\n",
            "ðŸš€ You're ready for production RAG systems!\n",
            "\n",
            "ðŸ’¡ Key learnings:\n",
            "   - Postprocessors improve result relevance and precision\n",
            "   - Different synthesizers work better for different query types\n",
            "   - Structured outputs enable reliable system integration\n",
            "   - Advanced techniques can be combined for production systems\n"
          ]
        }
      ],
      "source": [
        "# Final comparison: Basic vs Advanced RAG\n",
        "print(\"ðŸš€ Advanced RAG Techniques Assignment - Final Test\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Test queries for comparison\n",
        "test_queries = [\n",
        "    \"What are the key capabilities of AI agents?\",\n",
        "    \"How do you evaluate agent performance metrics?\",\n",
        "    \"Explain the benefits and challenges of multimodal AI systems\"\n",
        "]\n",
        "\n",
        "# Check if all components were created\n",
        "components_status = {\n",
        "    \"Basic Index\": index is not None,\n",
        "    \"Similarity Filter\": 'filtered_engine' in locals() and filtered_engine is not None,\n",
        "    \"TreeSummarize\": 'tree_engine' in locals() and tree_engine is not None,\n",
        "    \"Structured Output\": 'structured_program' in locals() and structured_program is not None,\n",
        "    \"Advanced Pipeline\": 'advanced_pipeline' in locals() and advanced_pipeline is not None\n",
        "}\n",
        "\n",
        "print(\"\\nðŸ“Š Component Status:\")\n",
        "for component, status in components_status.items():\n",
        "    status_icon = \"âœ…\" if status else \"âŒ\"\n",
        "    print(f\"   {status_icon} {component}\")\n",
        "\n",
        "# Create basic query engine for comparison\n",
        "if index:\n",
        "    print(\"\\nðŸ” Creating basic query engine for comparison...\")\n",
        "    basic_engine = index.as_query_engine(similarity_top_k=5)\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"ðŸ†š COMPARISON: Basic vs Advanced RAG\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    for i, query in enumerate(test_queries, 1):\n",
        "        print(f\"\\nðŸ“‹ Test Query {i}: '{query}'\")\n",
        "        print(\"-\" * 50)\n",
        "        \n",
        "        # Basic RAG\n",
        "        print(\"ðŸ”¹ Basic RAG:\")\n",
        "        if basic_engine:\n",
        "            # Uncomment when testing:\n",
        "            basic_response = basic_engine.query(query)\n",
        "            print(f\"   Response: {str(basic_response)[:200]}...\")\n",
        "            print(\"   (Standard vector search + simple response)\")\n",
        "        \n",
        "        # Advanced RAG (if implemented)\n",
        "        print(\"\\nðŸ”¸ Advanced RAG:\")\n",
        "        if components_status[\"Advanced Pipeline\"]:\n",
        "            # Uncomment when testing:\n",
        "            advanced_response = advanced_pipeline.query(query)\n",
        "            print(f\"   Response: {advanced_response}\")\n",
        "            print(\"   (Filtered + TreeSummarize + Structured output)\")\n",
        "        else:\n",
        "            print(\"   Complete the advanced pipeline function to test\")\n",
        "\n",
        "# Final status\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ðŸŽ¯ Assignment Status:\")\n",
        "completed_count = sum(components_status.values())\n",
        "total_count = len(components_status)\n",
        "\n",
        "print(f\"   Completed: {completed_count}/{total_count} components\")\n",
        "\n",
        "if completed_count == total_count:\n",
        "    print(\"\\nðŸŽ‰ Congratulations! You've mastered Advanced RAG Techniques!\")\n",
        "    print(\"   âœ… Node postprocessors for result filtering\")\n",
        "    print(\"   âœ… Response synthesizers for better answers\")\n",
        "    print(\"   âœ… Structured outputs for reliable data\")\n",
        "    print(\"   âœ… Advanced pipelines combining all techniques\")\n",
        "    print(\"\\nðŸš€ You're ready for production RAG systems!\")\n",
        "else:\n",
        "    missing = total_count - completed_count\n",
        "    print(f\"\\nðŸ“ Complete {missing} more components to finish the assignment:\")\n",
        "    for component, status in components_status.items():\n",
        "        if not status:\n",
        "            print(f\"   - {component}\")\n",
        "\n",
        "print(\"\\nðŸ’¡ Key learnings:\")\n",
        "print(\"   - Postprocessors improve result relevance and precision\")\n",
        "print(\"   - Different synthesizers work better for different query types\")\n",
        "print(\"   - Structured outputs enable reliable system integration\")\n",
        "print(\"   - Advanced techniques can be combined for production systems\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
