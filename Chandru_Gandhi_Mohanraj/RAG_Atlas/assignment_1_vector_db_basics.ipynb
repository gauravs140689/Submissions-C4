{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Assignment 1: Vector Database Creation and Retrieval\n",
        "## Day 6 Session 2 - RAG Fundamentals\n",
        "\n",
        "**OBJECTIVE:** Create a vector database from a folder of documents and implement basic retrieval functionality.\n",
        "\n",
        "**LEARNING GOALS:**\n",
        "- Understand document loading with SimpleDirectoryReader\n",
        "- Learn vector store setup with LanceDB\n",
        "- Implement vector index creation\n",
        "- Perform semantic search and retrieval\n",
        "\n",
        "**DATASET:** Use the data folder in `Day_6/session_2/data/` which contains multiple file types\n",
        "\n",
        "**INSTRUCTIONS:**\n",
        "1. Complete each function by replacing the TODO comments with actual implementation\n",
        "2. Run each cell after completing the function to test it\n",
        "3. The answers can be found in the existing notebooks in the `llamaindex_rag/` folder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/chandru/python-sandbox/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext, Settings\n",
        "from llama_index.vector_stores.lancedb import LanceDBVectorStore\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ÑπÔ∏è  OPENROUTER_API_KEY not found - that's OK for this assignment!\n",
            "   This assignment only uses local embeddings for vector operations.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 199/199 [00:00<00:00, 2797.85it/s, Materializing param=pooler.dense.weight]                               \n",
            "\u001b[1mBertModel LOAD REPORT\u001b[0m from: BAAI/bge-small-en-v1.5\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ LlamaIndex configured with local embeddings\n",
            "   Using BAAI/bge-small-en-v1.5 for document embeddings\n"
          ]
        }
      ],
      "source": [
        "# Configure LlamaIndex Settings (Using OpenRouter - No OpenAI API Key needed)\n",
        "def setup_llamaindex_settings():\n",
        "    \"\"\"\n",
        "    Configure LlamaIndex with local embeddings and OpenRouter for LLM.\n",
        "    This assignment focuses on vector database operations, so we'll use local embeddings only.\n",
        "    \"\"\"\n",
        "    # Check for OpenRouter API key (for future use, not needed for this basic assignment)\n",
        "    api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "    if not api_key:\n",
        "        print(\"‚ÑπÔ∏è  OPENROUTER_API_KEY not found - that's OK for this assignment!\")\n",
        "        print(\"   This assignment only uses local embeddings for vector operations.\")\n",
        "    \n",
        "    # Configure local embeddings (no API key required)\n",
        "    Settings.embed_model = HuggingFaceEmbedding(\n",
        "        model_name=\"BAAI/bge-small-en-v1.5\",\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "    \n",
        "    print(\"‚úÖ LlamaIndex configured with local embeddings\")\n",
        "    print(\"   Using BAAI/bge-small-en-v1.5 for document embeddings\")\n",
        "\n",
        "# Setup the configuration\n",
        "setup_llamaindex_settings()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Document Loading Function\n",
        "\n",
        "Complete the function below to load documents from a folder using `SimpleDirectoryReader`.\n",
        "\n",
        "**Note:** This assignment uses local embeddings only - no OpenAI API key required! We're configured to use OpenRouter for future LLM operations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ Loading documents from: ../data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/chandru/python-sandbox/.venv/lib/python3.12/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/Users/chandru/python-sandbox/.venv/lib/python3.12/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/Users/chandru/python-sandbox/.venv/lib/python3.12/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Successfully loaded 42 document nodes\n",
            "Loaded 42 documents\n",
            "üìä Sample Metadata: {'page_label': '1', 'file_name': 'AI_Agent_Frameworks.pdf', 'file_path': '/Users/chandru/python-sandbox/Outskill_AI_Acc_Assignments/RAG_Atlas_session_3/assignments/../data/AI_Agent_Frameworks.pdf', 'file_type': 'application/pdf', 'file_size': 360523, 'creation_date': '2026-02-07', 'last_modified_date': '2026-02-07'}\n",
            "üìù Preview: A Comprehensive Survey of AI Agent Frameworks\n",
            "and Their Applications in Financial Services\n",
            "Satyadhar Joshi\n",
            "Independent\n",
            "Alumnus, International MBA, Bar...\n"
          ]
        }
      ],
      "source": [
        "def load_documents_from_folder(folder_path: str):\n",
        "    \"\"\"\n",
        "    Load documents from a folder using SimpleDirectoryReader.\n",
        "    \n",
        "    TODO: Complete this function to load documents from the given folder path.\n",
        "    HINT: Use SimpleDirectoryReader with recursive parameter to load all files\n",
        "    \n",
        "    Args:\n",
        "        folder_path (str): Path to the folder containing documents\n",
        "        \n",
        "    Returns:\n",
        "        List of documents loaded from the folder\n",
        "    \"\"\"\n",
        "    print(f\"üìÇ Loading documents from: {folder_path}\")\n",
        "    \n",
        "    # Create SimpleDirectoryReader instance\n",
        "    reader = SimpleDirectoryReader(input_dir=folder_path, recursive=True)\n",
        "    \n",
        "    # Load and return documents\n",
        "    documents = reader.load_data()\n",
        "    \n",
        "    print(f\"‚úÖ Successfully loaded {len(documents)} document nodes\")\n",
        "    return documents\n",
        "\n",
        "# Test the function after you complete it\n",
        "test_folder = \"../data\"\n",
        "documents = load_documents_from_folder(test_folder)\n",
        "print(f\"Loaded {len(documents)} documents\")\n",
        "\n",
        "if documents:\n",
        "    print(f\"üìä Sample Metadata: {documents[0].metadata}\")\n",
        "    print(f\"üìù Preview: {documents[0].text[:150]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Vector Store Creation Function\n",
        "\n",
        "Complete the function below to create a LanceDB vector store.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-08 02:08:07,746 - WARNING - Table documents doesn't exist yet. Please add some data to create it.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LanceDB vector store initialized at ./assignment_vectordb\n",
            "Vector store created: True\n"
          ]
        }
      ],
      "source": [
        "def create_vector_store(db_path: str = \"./vectordb\", table_name: str = \"documents\"):\n",
        "    \"\"\"\n",
        "    Create a LanceDB vector store for storing document embeddings.\n",
        "    \n",
        "    TODO: Complete this function to create and configure a LanceDB vector store.\n",
        "    HINT: Use LanceDBVectorStore with uri and table_name parameters\n",
        "    \n",
        "    Args:\n",
        "        db_path (str): Path where the vector database will be stored\n",
        "        table_name (str): Name of the table in the vector database\n",
        "        \n",
        "    Returns:\n",
        "        LanceDBVectorStore: Configured vector store\n",
        "    \"\"\"\n",
        "    # TODO: Create the directory if it doesn't exist\n",
        "    Path(db_path).mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # TODO: Create vector store\n",
        "    vector_store = LanceDBVectorStore(uri=db_path, table_name=table_name)\n",
        "    \n",
        "    print(f\"LanceDB vector store initialized at {db_path}\")\n",
        "    return vector_store\n",
        "\n",
        "# Test the function after you complete it\n",
        "vector_store = create_vector_store(\"./assignment_vectordb\")\n",
        "print(f\"Vector store created: {vector_store is not None}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Vector Index Creation Function\n",
        "\n",
        "Complete the function below to create a vector index from documents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Parsing nodes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 42/42 [00:02<00:00, 15.93it/s]\n",
            "Generating embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55/55 [00:01<00:00, 33.44it/s]\n",
            "2026-02-08 02:11:34,726 - INFO - Create new table documents adding data.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created vector index from 42 documents\n",
            "Vector index created: True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[90m[\u001b[0m2026-02-08T07:11:34Z \u001b[33mWARN \u001b[0m lance::dataset::write::insert\u001b[90m]\u001b[0m No existing dataset at /Users/chandru/python-sandbox/Outskill_AI_Acc_Assignments/RAG_Atlas_session_3/assignments/assignment_vectordb/documents.lance, it will be created\n"
          ]
        }
      ],
      "source": [
        "def create_vector_index(documents: List, vector_store):\n",
        "    \"\"\"\n",
        "    Create a vector index from documents using the provided vector store.\n",
        "    \n",
        "    TODO: Complete this function to create a VectorStoreIndex from documents.\n",
        "    HINT: Create StorageContext with vector_store, then use VectorStoreIndex.from_documents()\n",
        "    \n",
        "    Args:\n",
        "        documents: List of documents to index\n",
        "        vector_store: LanceDB vector store to use for storage\n",
        "        \n",
        "    Returns:\n",
        "        VectorStoreIndex: The created vector index\n",
        "    \"\"\"\n",
        "    # Create storage context with vector store\n",
        "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "    \n",
        "    # Create index from documents\n",
        "    index = VectorStoreIndex.from_documents(documents, storage_context=storage_context, show_progress=True)\n",
        "    \n",
        "    # return index\n",
        "    \n",
        "    # PLACEHOLDER - Replace with actual implementation\n",
        "    print(f\"Created vector index from {len(documents)} documents\")\n",
        "    return index\n",
        "\n",
        "# Test the function after you complete it (will only work after previous functions are completed)\n",
        "if documents and vector_store:\n",
        "    index = create_vector_index(documents, vector_store)\n",
        "    print(f\"Vector index created: {index is not None}\")\n",
        "else:\n",
        "    print(\"Complete previous functions first to test this one\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Document Search Function\n",
        "\n",
        "Complete the function below to search for relevant documents using the vector index.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-08 02:14:32,604 - INFO - query_type :, vector\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Search for 'What are AI agents?' in index returned 2 results\n",
            "Found 2 results for query: 'What are AI agents?'\n",
            "Result 1: agent-personas or the user is not needed, multi-agent architectures tend to thrive more when collabo...\n",
            "Result 2: task. In single agent patterns there is no feedback mechanism from other AI agents; however, there m...\n"
          ]
        }
      ],
      "source": [
        "def search_documents(index, query: str, top_k: int = 3):\n",
        "    \"\"\"\n",
        "    Search for relevant documents using the vector index.\n",
        "    \n",
        "    TODO: Complete this function to perform semantic search on the index.\n",
        "    HINT: Use index.as_retriever() with similarity_top_k parameter, then retrieve(query)\n",
        "    \n",
        "    Args:\n",
        "        index: Vector index to search\n",
        "        query (str): Search query\n",
        "        top_k (int): Number of top results to return\n",
        "        \n",
        "    Returns:\n",
        "        List of retrieved document nodes\n",
        "    \"\"\"\n",
        "    # Create retriever from index\n",
        "    retriever = index.as_retriever(similarity_top_k=top_k)\n",
        "    \n",
        "    # Retrieve documents for the query\n",
        "    results = retriever.retrieve(query)\n",
        "    \n",
        "    # return results\n",
        "    \n",
        "    # PLACEHOLDER - Replace with actual implementation\n",
        "    print(f\"Search for '{query}' in index returned {len(results)} results\")\n",
        "    return results\n",
        "\n",
        "# Test the function after you complete it (will only work after all previous functions are completed)\n",
        "if 'index' in locals() and index is not None:\n",
        "    test_query = \"What are AI agents?\"\n",
        "    results = search_documents(index, test_query, top_k=2)\n",
        "    print(f\"Found {len(results)} results for query: '{test_query}'\")\n",
        "    for i, result in enumerate(results, 1):\n",
        "        print(f\"Result {i}: {result.text[:100] if hasattr(result, 'text') else 'No text'}...\")\n",
        "else:\n",
        "    print(\"Complete all previous functions first to test this one\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Final Test - Complete Pipeline\n",
        "\n",
        "Once you've completed all the functions above, run this cell to test the complete pipeline with multiple search queries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Testing Complete Vector Database Pipeline\n",
            "==================================================\n",
            "\n",
            "üìÇ Step 1: Loading documents...\n",
            "üìÇ Loading documents from: ../data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/chandru/python-sandbox/.venv/lib/python3.12/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/Users/chandru/python-sandbox/.venv/lib/python3.12/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "/Users/chandru/python-sandbox/.venv/lib/python3.12/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Successfully loaded 42 document nodes\n",
            "   Loaded 42 documents\n",
            "\n",
            "üóÑÔ∏è Step 2: Creating vector store...\n",
            "LanceDB vector store initialized at ./assignment_vectordb\n",
            "   Vector store status: ‚úÖ Created\n",
            "\n",
            "üîó Step 3: Creating vector index...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Parsing nodes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 42/42 [00:00<00:00, 1911.53it/s]\n",
            "Generating embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55/55 [00:01<00:00, 37.75it/s]\n",
            "2026-02-08 02:15:10,531 - INFO - query_type :, vector\n",
            "2026-02-08 02:15:10,646 - INFO - query_type :, vector\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created vector index from 42 documents\n",
            "   Index status: ‚úÖ Created\n",
            "\n",
            "üîç Step 4: Testing search functionality...\n",
            "\n",
            "   üîé Query: 'What are AI agents?'\n",
            "Search for 'What are AI agents?' in index returned 1 results\n",
            "      1. agent-personas or the user is not needed, multi-agent architectures tend to thrive more when collabo... (Score: 0.6183)\n",
            "\n",
            "   üîé Query: 'How to evaluate agent performance?'\n",
            "Search for 'How to evaluate agent performance?' in index returned 1 results\n",
            "      1. steps, but the answers are limited to Yes/No responses [7]. As the industry continues to pivot towar... (Score: 0.6642)\n",
            "\n",
            "   üîé Query: 'Italian recipes and cooking'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-02-08 02:15:10,901 - INFO - query_type :, vector\n",
            "2026-02-08 02:15:10,913 - INFO - query_type :, vector\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Search for 'Italian recipes and cooking' in index returned 1 results\n",
            "      1. # üçù Classic Spaghetti Carbonara Recipe\n",
            "\n",
            "## Ingredients\n",
            "- 400g spaghetti pasta\n",
            "- 4 large egg yolks\n",
            "- ... (Score: 0.6271)\n",
            "\n",
            "   üîé Query: 'Financial analysis and investment'\n",
            "Search for 'Financial analysis and investment' in index returned 1 results\n",
            "      1. Stock, AAPL, Apple Inc, 10000, 12500, 25.0, Medium\n",
            "Stock, GOOGL, Alphabet Inc, 8000, 9200, 15.0, Med... (Score: 0.5706)\n",
            "\n",
            "==================================================\n",
            "üéØ Assignment Status:\n",
            "   Documents loaded: ‚úÖ\n",
            "   Vector store created: ‚úÖ\n",
            "   Index created: ‚úÖ\n",
            "   Search working: ‚úÖ\n",
            "\n",
            "üéâ Congratulations! You've successfully completed the assignment!\n",
            "   You've built a complete vector database with search functionality!\n"
          ]
        }
      ],
      "source": [
        "# Final test of the complete pipeline\n",
        "print(\"üöÄ Testing Complete Vector Database Pipeline\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Re-run the complete pipeline to ensure everything works\n",
        "data_folder = \"../data\"\n",
        "vector_db_path = \"./assignment_vectordb\"\n",
        "\n",
        "# Step 1: Load documents\n",
        "print(\"\\nüìÇ Step 1: Loading documents...\")\n",
        "documents = load_documents_from_folder(data_folder)\n",
        "print(f\"   Loaded {len(documents)} documents\")\n",
        "\n",
        "# Step 2: Create vector store\n",
        "print(\"\\nüóÑÔ∏è Step 2: Creating vector store...\")\n",
        "vector_store = create_vector_store(vector_db_path)\n",
        "print(\"   Vector store status:\", \"‚úÖ Created\" if vector_store else \"‚ùå Failed\")\n",
        "\n",
        "# Step 3: Create vector index\n",
        "print(\"\\nüîó Step 3: Creating vector index...\")\n",
        "if documents and vector_store:\n",
        "    index = create_vector_index(documents, vector_store)\n",
        "    print(\"   Index status:\", \"‚úÖ Created\" if index else \"‚ùå Failed\")\n",
        "else:\n",
        "    index = None\n",
        "    print(\"   ‚ùå Cannot create index - missing documents or vector store\")\n",
        "\n",
        "# Step 4: Test multiple search queries\n",
        "print(\"\\nüîç Step 4: Testing search functionality...\")\n",
        "if index:\n",
        "    search_queries = [\n",
        "        \"What are AI agents?\",\n",
        "        \"How to evaluate agent performance?\", \n",
        "        \"Italian recipes and cooking\",\n",
        "        \"Financial analysis and investment\"\n",
        "    ]\n",
        "    \n",
        "    for query in search_queries:\n",
        "        print(f\"\\n   üîé Query: '{query}'\")\n",
        "        results = search_documents(index, query, top_k=2)\n",
        "        \n",
        "        if results:\n",
        "            for i, result in enumerate(results, 1):\n",
        "                text_preview = result.text[:100] if hasattr(result, 'text') else \"No text available\"\n",
        "                score = f\" (Score: {result.score:.4f})\" if hasattr(result, 'score') else \"\"\n",
        "                print(f\"      {i}. {text_preview}...{score}\")\n",
        "        else:\n",
        "            print(\"      No results found\")\n",
        "else:\n",
        "    print(\"   ‚ùå Cannot test search - index not created\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"üéØ Assignment Status:\")\n",
        "print(f\"   Documents loaded: {'‚úÖ' if documents else '‚ùå'}\")\n",
        "print(f\"   Vector store created: {'‚úÖ' if vector_store else '‚ùå'}\")\n",
        "print(f\"   Index created: {'‚úÖ' if index else '‚ùå'}\")\n",
        "print(f\"   Search working: {'‚úÖ' if index else '‚ùå'}\")\n",
        "\n",
        "if documents and vector_store and index:\n",
        "    print(\"\\nüéâ Congratulations! You've successfully completed the assignment!\")\n",
        "    print(\"   You've built a complete vector database with search functionality!\")\n",
        "else:\n",
        "    print(\"\\nüìù Please complete the TODO functions above to finish the assignment.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
