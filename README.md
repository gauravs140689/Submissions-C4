# ğŸ•µï¸â€â™‚ï¸ Agentic Research Engine (Group 4)

A powerful, autonomous deep research system powered by **AI Agents**. This engine can perform comprehensive web research, verify facts, detect contradictions, and synthesize findings into a cited reportâ€”all through a user-friendly Streamlit interface.

## ğŸš€ Key Features

-   **Multi-Step Research & Planning**: Breaks down complex queries into sub-questions using a **Search Strategist**.
-   **Autonomous Information Gathering**: Fetches data from **Tavily**, **Wikipedia**, and **Arxiv**.
-   **Intelligent Claim Extraction**: Isolates atomic claims from raw text for granular analysis.
-   **Contradiction Detection**: Automatically spots conflicting information across sources and triggers specific resolution loops.
-   **Hallucination Check (De-Bunker)**: Verifies claims against source text using **Cosine Similarity** (Fast Pass) and LLM verification (Slow Pass).
-   **Dynamic LLM Switching**: Seamlessly toggle between **Cloud Models (OpenRouter)** and **Local LLMs (LM Studio)** via the UI.
-   **Live Metrics Dashboard**: Track time, tokens, and tool usage in real-time.

---

## ğŸ—ï¸ Architecture

The system is built on **LangGraph** with a stateful workflow of specialized agents:

```mermaid
graph TD
    Start([User Query]) --> Strategist[Search Strategist]
    Strategist --> Gatherer[Information Gatherer]
    Gatherer --> Extractor[Claim Extractor]
    Extractor --> Detector[Conflict Detector]
    
    Detector -- "Conflict Found" --> Loop{Loop?}
    Loop -- "Yes" --> Strategist
    Loop -- "No" --> Verifier[Source Verifier]
    Detector -- "No Conflict" --> Verifier
    
    Verifier --> Synthesizer[Knowledge Synthesizer]
    Synthesizer --> Designer[Narrative Designer]
    Designer --> End([Final Report])
```

### ğŸ¤– The Agents
1.  **Search Strategist** (`research_strategist.py`): Decomposes the main query into targeted sub-questions.
2.  **Information Gatherer** (`information_gatherer.py`): Executes searches using configured tools (Tavily, Wiki, Arxiv).
3.  **Claim Extractor** (`claim_extractor.py`): Processes raw content to extract specific, verifiable claims.
4.  **Conflict Detector** (`conflict_detector.py`): Analyzes claims to find contradictions.
5.  **Source Verifier** (`source_verifier.py`): Checks claims against source text to prevent hallucinations.
6.  **Knowledge Synthesizer** (`knowledge_synthesizer.py`): Aggregates verified claims into a coherent answer.
7.  **Narrative Designer** (`narrative_designer.py`): Formats the final output into a professional markdown report.

---

## ğŸ› ï¸ Installation

### Prerequisites
-   Python 3.10+
-   [LM Studio](https://lmstudio.ai/) (Optional, for local LLMs)

### 1. Clone the Repository
```bash
git clone <repository-url>
cd <repository-folder>
```

### 2. Set Up Virtual Environment
```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

---

## âš™ï¸ Configuration

### 1. Environment Variables
Create a `.env` file in the root directory for your API keys:

```ini
# Required for Search
TAVILY_API_KEY="tvly-..."

# Required for Cloud LLMs (OpenRouter)
OPENROUTER_API_KEY="sk-or-..."
OPENROUTER_BASE_URL="https://openrouter.ai/api/v1"
LLM_MODEL="google/gemini-2.0-flash-lite-preview-02-05:free"

# Detailed Configuration
CONTRADICTION_THRESHOLD=0.9
MAX_SUB_QUESTIONS=5
```

### 2. Local LLM Configuration (`config.env`)
The system also reads from `config.env` for local settings. This file is pre-configured for LM Studio:

```ini
# Local Specifics
LOCAL_LLM_BASE_URL="http://localhost:1233/v1"
LOCAL_LLM_MODEL="local-model"
```
*Note: Ensure LM Studio is running its server on port `1233`.*

---

## ğŸ–¥ï¸ Usage

### 1. Start the Application
Run the Streamlit UI with the helper script:
```bash
./run_ui.sh
```
Or manually:
```bash
streamlit run app.py
```

### 2. Using the Interface
1.  **Select Provider**: Choose between **OpenRouter** (Cloud) or **Local (LM Studio)** in the sidebar.
2.  **Enter Query**: Type your research question (e.g., *"What is the current state of Quantum Computing?"*).
3.  **Start Researchers**: Click "Start Research" and watch the agents work in the logs.
4.  **View Results**:
    -   **Final Report**: The synthesized article.
    -   **Claims**: All extracted claims with confidence scores.
    -   **Contradictions**: Any conflicts found during research.

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ app.py                  # Main Streamlit Application
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/             # Agent Implementations
â”‚   â”‚   â”œâ”€â”€ research_strategist.py
â”‚   â”‚   â”œâ”€â”€ information_gatherer.py
â”‚   â”‚   â”œâ”€â”€ claim_extractor.py
â”‚   â”‚   â”œâ”€â”€ conflict_detector.py
â”‚   â”‚   â”œâ”€â”€ source_verifier.py
â”‚   â”‚   â”œâ”€â”€ knowledge_synthesizer.py
â”‚   â”‚   â””â”€â”€ narrative_designer.py
â”‚   â”œâ”€â”€ config.py           # Configuration Management
â”‚   â”œâ”€â”€ graph.py            # LangGraph Orchestration
â”‚   â””â”€â”€ state.py            # Global State Definition
â”œâ”€â”€ config.env              # Local LLM Config
â”œâ”€â”€ requirements.txt        # Python Dependencies
â””â”€â”€ run_ui.sh               # Startup Script
```

---

## ï¿½ Methodology & Attribution

This project follows the **Get Shit Done (GSD)** methodology, designed for transparency and efficiency in autonomous development.

-   **Original Methodology**: [Get Shit Done](https://github.com/gsd-build/get-shit-done)
-   **Adapted for Antigravity**: [GSD for Antigravity](https://github.com/toonight/get-shit-done-for-antigravity)

We utilize this framework to ensure rigorous planning, state management, and empirical verification throughout the development lifecycle.

---

## ï¿½ğŸ¤ Contributing
1.  Fork the repo.
2.  Create your feature branch (`git checkout -b feature/AmazingFeature`).
3.  Commit your changes (`git commit -m 'Add some AmazingFeature'`).
4.  Push to the branch (`git push origin feature/AmazingFeature`).
5.  Open a Pull Request.

---

**Built with â¤ï¸ for Outskill Hackathon - Group 4**
