{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC4UaZjz8whb"
      },
      "source": [
        "# Assignment 1: Vector Database Creation and Retrieval\n",
        "## Day 6 Session 2 - RAG Fundamentals\n",
        "\n",
        "**OBJECTIVE:** Create a vector database from a folder of documents and implement basic retrieval functionality.\n",
        "\n",
        "**LEARNING GOALS:**\n",
        "- Understand document loading with SimpleDirectoryReader\n",
        "- Learn vector store setup with LanceDB\n",
        "- Implement vector index creation\n",
        "- Perform semantic search and retrieval\n",
        "\n",
        "**DATASET:** Use the data folder in `Day_6/session_2/data/` which contains multiple file types\n",
        "\n",
        "**INSTRUCTIONS:**\n",
        "1. Complete each function by replacing the TODO comments with actual implementation\n",
        "2. Run each cell after completing the function to test it\n",
        "3. The answers can be found in the existing notebooks in the `llamaindex_rag/` folder\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeKfiwFn_MWw",
        "outputId": "bed62f01-ee6e-4b29-c3ed-a2385d04c82c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -r \"/content/drive/MyDrive/outskill_c4/requirements.txt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "581rKe1Y_eP2",
        "outputId": "6518c439-b360-4405-bc93-a54c6230fbc5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m182.0/182.0 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: huggingface-hub 1.3.7 does not provide the extra 'inference'\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.2/47.2 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m278.0/278.0 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m116.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m303.3/303.3 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.3/188.3 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.6/57.6 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.8/96.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m329.1/329.1 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McKtnBLG8whc",
        "outputId": "2e803255-bf4c-45d1-b232-e7b00a3388a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext, Settings\n",
        "from llama_index.vector_stores.lancedb import LanceDBVectorStore\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "print(\"âœ… Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# securely input your key\n",
        "os.environ[\"Oprnrouter\"] = getpass(\"Enter your OpenRouter key\")\n",
        "print(\"âœ“ OpenrRouter key set successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O79FvSVpENCD",
        "outputId": "345a297e-d908-4ad1-e7ed-5ece47f0f10f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your OpenRouter keyÂ·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "âœ“ OpenrRouter key set successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "fbbc7295485641d096108cb4fa7b3637",
            "aa37fa4b227f42dcbddfc8e00153dd01",
            "33cbf92b2bd344778a6a5045a1a04658",
            "9e4f0025ba474e97ab30ce7ad2c90c98",
            "272dc5d5602d408f85ad12db1b5b6cf3",
            "07840be26f7e494a8304ff650d800a7b",
            "4d1d38725bfc469e9b4bb6e787297f6c",
            "ad42af8e7a914be78c9a996cd166010b",
            "f696a1d6470d4582a6666eee7307759c",
            "d1e5cbd6cef84a55b4e07a26c21d552c",
            "e7ef8502621945749bec744d6a85f9e0"
          ]
        },
        "id": "CNcbla828whd",
        "outputId": "de53d338-dc98-4470-b6ab-257854c04136"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbbc7295485641d096108cb4fa7b3637"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertModel LOAD REPORT from: BAAI/bge-small-en-v1.5\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… LlamaIndex configured with local embeddings\n",
            "   Using BAAI/bge-small-en-v1.5 for document embeddings\n"
          ]
        }
      ],
      "source": [
        "# Configure LlamaIndex Settings (Using OpenRouter - No OpenAI API Key needed)\n",
        "def setup_llamaindex_settings():\n",
        "    \"\"\"\n",
        "    Configure LlamaIndex with local embeddings and OpenRouter for LLM.\n",
        "    This assignment focuses on vector database operations, so we'll use local embeddings only.\n",
        "    \"\"\"\n",
        "    # Check for OpenRouter API key (for future use, not needed for this basic assignment)\n",
        "    api_key = os.getenv(\"Oprnrouter\")\n",
        "    if not api_key:\n",
        "        print(\"â„¹ï¸  OPENROUTER_API_KEY not found - that's OK for this assignment!\")\n",
        "        print(\"   This assignment only uses local embeddings for vector operations.\")\n",
        "\n",
        "    # Configure local embeddings (no API key required)\n",
        "    Settings.embed_model = HuggingFaceEmbedding(\n",
        "        model_name=\"BAAI/bge-small-en-v1.5\",\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "\n",
        "    print(\"âœ… LlamaIndex configured with local embeddings\")\n",
        "    print(\"   Using BAAI/bge-small-en-v1.5 for document embeddings\")\n",
        "\n",
        "# Setup the configuration\n",
        "setup_llamaindex_settings()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHAr3RPK8whd"
      },
      "source": [
        "## 1. Document Loading Function\n",
        "\n",
        "Complete the function below to load documents from a folder using `SimpleDirectoryReader`.\n",
        "\n",
        "**Note:** This assignment uses local embeddings only - no OpenAI API key required! We're configured to use OpenRouter for future LLM operations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExnRmASH8whe",
        "outputId": "6e4c52a3-1ef2-499e-d21a-76bae18f9005"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 229 documents\n"
          ]
        }
      ],
      "source": [
        "def load_documents_from_folder(folder_path: str):\n",
        "    \"\"\"\n",
        "    Load documents from a folder using SimpleDirectoryReader.\n",
        "\n",
        "    TODO: Complete this function to load documents from the given folder path.\n",
        "    HINT: Use SimpleDirectoryReader with recursive parameter to load all files\n",
        "\n",
        "    Args:\n",
        "        folder_path (str): Path to the folder containing documents\n",
        "\n",
        "    Returns:\n",
        "        List of documents loaded from the folder\n",
        "    \"\"\"\n",
        "    # TODO: Create SimpleDirectoryReader instance\n",
        "    from llama_index.core import SimpleDirectoryReader\n",
        "    reader = SimpleDirectoryReader(\n",
        "        input_dir=folder_path,\n",
        "        recursive=True\n",
        "        # Let SimpleDirectoryReader handle all supported file types automatically\n",
        "    )\n",
        "\n",
        "\n",
        "    # TODO: Load and return documents\n",
        "    documents = reader.load_data()\n",
        "\n",
        "    return documents\n",
        "\n",
        "    # PLACEHOLDER - Replace with actual implementation\n",
        "    print(f\"TODO: Load documents from {folder_path}\")\n",
        "    return []\n",
        "\n",
        "# Test the function after you complete it\n",
        "test_folder = \"/content/drive/MyDrive/outskill_c4/paper/\"\n",
        "documents = load_documents_from_folder(test_folder)\n",
        "print(f\"Loaded {len(documents)} documents\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20SMka368whe"
      },
      "source": [
        "## 2. Vector Store Creation Function\n",
        "\n",
        "Complete the function below to create a LanceDB vector store.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhZ5mNiJ8whe",
        "outputId": "aaaafbc1-2e9e-405e-d109-46bdab279f0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:llama_index.vector_stores.lancedb.base:Table documents doesn't exist yet. Please add some data to create it.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector store created: True\n"
          ]
        }
      ],
      "source": [
        "def create_vector_store(db_path: str = \"./vectordb\", table_name: str = \"documents\"):\n",
        "    \"\"\"\n",
        "    Create a LanceDB vector store for storing document embeddings.\n",
        "\n",
        "    TODO: Complete this function to create and configure a LanceDB vector store.\n",
        "    HINT: Use LanceDBVectorStore with uri and table_name parameters\n",
        "\n",
        "    Args:\n",
        "        db_path (str): Path where the vector database will be stored\n",
        "        table_name (str): Name of the table in the vector database\n",
        "\n",
        "    Returns:\n",
        "        LanceDBVectorStore: Configured vector store\n",
        "    \"\"\"\n",
        "\n",
        "    import lancedb\n",
        "    # TODO: Create the directory if it doesn't exist\n",
        "    Path(db_path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # TODO: Create vector store\n",
        "    vector_store = LanceDBVectorStore(\n",
        "            uri=str(db_path),\n",
        "            table_name=\"documents\"\n",
        "        )\n",
        "\n",
        "    return vector_store\n",
        "\n",
        "    # PLACEHOLDER - Replace with actual implementation\n",
        "    print(f\"TODO: Create vector store at {db_path}\")\n",
        "    return None\n",
        "\n",
        "# Test the function after you complete it\n",
        "vector_store = create_vector_store(\"./assignment_vectordb\")\n",
        "print(f\"Vector store created: {vector_store is not None}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4Jd41eZ8whe"
      },
      "source": [
        "## 3. Vector Index Creation Function\n",
        "\n",
        "Complete the function below to create a vector index from documents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d4jKLOg8whe",
        "outputId": "a54e1ce9-e3ad-4eb0-934b-3c16f120df34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector index created: True\n"
          ]
        }
      ],
      "source": [
        "def create_vector_index(documents: List, vector_store):\n",
        "    \"\"\"\n",
        "    Create a vector index from documents using the provided vector store.\n",
        "\n",
        "    TODO: Complete this function to create a VectorStoreIndex from documents.\n",
        "    HINT: Create StorageContext with vector_store, then use VectorStoreIndex.from_documents()\n",
        "\n",
        "    Args:\n",
        "        documents: List of documents to index\n",
        "        vector_store: LanceDB vector store to use for storage\n",
        "\n",
        "    Returns:\n",
        "        VectorStoreIndex: The created vector index\n",
        "    \"\"\"\n",
        "    # TODO: Create storage context with vector store\n",
        "    storage_context = StorageContext.from_defaults(\n",
        "                vector_store=vector_store\n",
        "            )\n",
        "\n",
        "    # TODO: Create index from documents\n",
        "\n",
        "    index = VectorStoreIndex.from_documents(\n",
        "                documents,\n",
        "                storage_context=storage_context\n",
        "            )\n",
        "\n",
        "    return index\n",
        "\n",
        "    # PLACEHOLDER - Replace with actual implementation\n",
        "    print(f\"TODO: Create vector index from {len(documents)} documents\")\n",
        "    return None\n",
        "\n",
        "# Test the function after you complete it (will only work after previous functions are completed)\n",
        "if documents and vector_store:\n",
        "    index = create_vector_index(documents, vector_store)\n",
        "    print(f\"Vector index created: {index is not None}\")\n",
        "else:\n",
        "    print(\"Complete previous functions first to test this one\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ivf-vMj8whe"
      },
      "source": [
        "## 4. Document Search Function\n",
        "\n",
        "Complete the function below to search for relevant documents using the vector index.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gx4g056P8whf",
        "outputId": "1cc2e0c4-5bed-4a30-8c5e-98f23c5dccd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2 results for query: 'What are AI agents?'\n",
            "Result 1: AI Agents vs. Agentic AI: A Conceptual\n",
            "Taxonomy, Applications and Challenges\n",
            "Ranjan Sapkota âˆ—â€¡, Kons...\n",
            "Result 2: AI Agents\n",
            "&\n",
            "Agentic AI\n",
            "Architecture\n",
            "Mechanisms\n",
            "Scope/\n",
            "Complexity\n",
            "Interaction\n",
            "Autonomy\n",
            "Fig. 2: Mindma...\n"
          ]
        }
      ],
      "source": [
        "def search_documents(index, query: str, top_k: int = 3):\n",
        "    \"\"\"\n",
        "    Search for relevant documents using the vector index.\n",
        "\n",
        "    TODO: Complete this function to perform semantic search on the index.\n",
        "    HINT: Use index.as_retriever() with similarity_top_k parameter, then retrieve(query)\n",
        "\n",
        "    Args:\n",
        "        index: Vector index to search\n",
        "        query (str): Search query\n",
        "        top_k (int): Number of top results to return\n",
        "\n",
        "    Returns:\n",
        "        List of retrieved document nodes\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: Create retriever from index\n",
        "    retriever = index.as_retriever(similarity_top_k=top_k)\n",
        "\n",
        "    # TODO: Retrieve documents for the query\n",
        "    results = retriever.retrieve(query)\n",
        "\n",
        "    return results\n",
        "\n",
        "# Test the function after you complete it (will only work after all previous functions are completed)\n",
        "if 'index' in locals() and index is not None:\n",
        "    test_query = \"What are AI agents?\"\n",
        "    results = search_documents(index, test_query, top_k=2)\n",
        "    print(f\"Found {len(results)} results for query: '{test_query}'\")\n",
        "    for i, result in enumerate(results, 1):\n",
        "        # Access the node's text attribute for printing, as retrieve returns NodeWithScore objects\n",
        "        print(f\"Result {i}: {result.node.text[:100] if hasattr(result.node, 'text') else 'No text'}...\")\n",
        "else:\n",
        "    print(\"Complete all previous functions first to test this one\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G88ApYdC8whf"
      },
      "source": [
        "## 5. Final Test - Complete Pipeline\n",
        "\n",
        "Once you've completed all the functions above, run this cell to test the complete pipeline with multiple search queries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-JKSkg-8whf",
        "outputId": "f1ca15ca-50c7-461e-81ea-bb47179a0165"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Testing Complete Vector Database Pipeline\n",
            "==================================================\n",
            "\n",
            "ğŸ“‚ Step 1: Loading documents...\n",
            "   Loaded 229 documents\n",
            "\n",
            "ğŸ—„ï¸ Step 2: Creating vector store...\n",
            "   Vector store status: âœ… Created\n",
            "\n",
            "ğŸ”— Step 3: Creating vector index...\n",
            "   Index status: âœ… Created\n",
            "\n",
            "ğŸ” Step 4: Testing search functionality...\n",
            "\n",
            "   ğŸ” Query: 'What are AI agents?'\n",
            "      1. AI Agents vs. Agentic AI: A Conceptual\n",
            "Taxonomy, Applications and Challenges\n",
            "Ranjan Sapkota âˆ—â€¡, Kons... (Score: 0.6707)\n",
            "\n",
            "   ğŸ” Query: 'How to evaluate agent performance?'\n",
            "      1. steps, but the answers are limited to Yes/No responses [7]. As the industry continues to pivot towar... (Score: 0.6822)\n",
            "\n",
            "   ğŸ” Query: 'Italian recipes and cooking'\n",
            "      1. Zhao et al., â€œChemagent: Self-updating library in\n",
            "large language models improves chemical reasoning,... (Score: 0.4465)\n",
            "\n",
            "   ğŸ” Query: 'Financial analysis and investment'\n",
            "      1. Moving beyond traditional single-agent models, the system\n",
            "features configurable agent groups with di... (Score: 0.5932)\n",
            "\n",
            "==================================================\n",
            "ğŸ¯ Assignment Status:\n",
            "   Documents loaded: âœ…\n",
            "   Vector store created: âœ…\n",
            "   Index created: âœ…\n",
            "   Search working: âœ…\n",
            "\n",
            "ğŸ‰ Congratulations! You've successfully completed the assignment!\n",
            "   You've built a complete vector database with search functionality!\n"
          ]
        }
      ],
      "source": [
        "# Final test of the complete pipeline\n",
        "print(\"ğŸš€ Testing Complete Vector Database Pipeline\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Re-run the complete pipeline to ensure everything works\n",
        "data_folder = \"/content/drive/MyDrive/outskill_c4/paper/\"\n",
        "vector_db_path = \"./assignment_vectordb\"\n",
        "\n",
        "# Step 1: Load documents\n",
        "print(\"\\nğŸ“‚ Step 1: Loading documents...\")\n",
        "documents = load_documents_from_folder(data_folder)\n",
        "print(f\"   Loaded {len(documents)} documents\")\n",
        "\n",
        "# Step 2: Create vector store\n",
        "print(\"\\nğŸ—„ï¸ Step 2: Creating vector store...\")\n",
        "vector_store = create_vector_store(vector_db_path)\n",
        "print(\"   Vector store status:\", \"âœ… Created\" if vector_store else \"âŒ Failed\")\n",
        "\n",
        "# Step 3: Create vector index\n",
        "print(\"\\nğŸ”— Step 3: Creating vector index...\")\n",
        "if documents and vector_store:\n",
        "    index = create_vector_index(documents, vector_store)\n",
        "    print(\"   Index status:\", \"âœ… Created\" if index else \"âŒ Failed\")\n",
        "else:\n",
        "    index = None\n",
        "    print(\"   âŒ Cannot create index - missing documents or vector store\")\n",
        "\n",
        "# Step 4: Test multiple search queries\n",
        "print(\"\\nğŸ” Step 4: Testing search functionality...\")\n",
        "if index:\n",
        "    search_queries = [\n",
        "        \"What are AI agents?\",\n",
        "        \"How to evaluate agent performance?\",\n",
        "        \"Italian recipes and cooking\",\n",
        "        \"Financial analysis and investment\"\n",
        "    ]\n",
        "\n",
        "    for query in search_queries:\n",
        "        print(f\"\\n   ğŸ” Query: '{query}'\")\n",
        "        results = search_documents(index, query, top_k=2)\n",
        "\n",
        "        if results:\n",
        "            for i, result in enumerate(results, 1):\n",
        "                text_preview = result.text[:100] if hasattr(result, 'text') else \"No text available\"\n",
        "                score = f\" (Score: {result.score:.4f})\" if hasattr(result, 'score') else \"\"\n",
        "                print(f\"      {i}. {text_preview}...{score}\")\n",
        "        else:\n",
        "            print(\"      No results found\")\n",
        "else:\n",
        "    print(\"   âŒ Cannot test search - index not created\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"ğŸ¯ Assignment Status:\")\n",
        "print(f\"   Documents loaded: {'âœ…' if documents else 'âŒ'}\")\n",
        "print(f\"   Vector store created: {'âœ…' if vector_store else 'âŒ'}\")\n",
        "print(f\"   Index created: {'âœ…' if index else 'âŒ'}\")\n",
        "print(f\"   Search working: {'âœ…' if index else 'âŒ'}\")\n",
        "\n",
        "if documents and vector_store and index:\n",
        "    print(\"\\nğŸ‰ Congratulations! You've successfully completed the assignment!\")\n",
        "    print(\"   You've built a complete vector database with search functionality!\")\n",
        "else:\n",
        "    print(\"\\nğŸ“ Please complete the TODO functions above to finish the assignment.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "accelerator",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fbbc7295485641d096108cb4fa7b3637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa37fa4b227f42dcbddfc8e00153dd01",
              "IPY_MODEL_33cbf92b2bd344778a6a5045a1a04658",
              "IPY_MODEL_9e4f0025ba474e97ab30ce7ad2c90c98"
            ],
            "layout": "IPY_MODEL_272dc5d5602d408f85ad12db1b5b6cf3"
          }
        },
        "aa37fa4b227f42dcbddfc8e00153dd01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07840be26f7e494a8304ff650d800a7b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4d1d38725bfc469e9b4bb6e787297f6c",
            "value": "Loadingâ€‡weights:â€‡100%"
          }
        },
        "33cbf92b2bd344778a6a5045a1a04658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad42af8e7a914be78c9a996cd166010b",
            "max": 199,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f696a1d6470d4582a6666eee7307759c",
            "value": 199
          }
        },
        "9e4f0025ba474e97ab30ce7ad2c90c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1e5cbd6cef84a55b4e07a26c21d552c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e7ef8502621945749bec744d6a85f9e0",
            "value": "â€‡199/199â€‡[00:00&lt;00:00,â€‡527.33it/s,â€‡Materializingâ€‡param=pooler.dense.weight]"
          }
        },
        "272dc5d5602d408f85ad12db1b5b6cf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07840be26f7e494a8304ff650d800a7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d1d38725bfc469e9b4bb6e787297f6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad42af8e7a914be78c9a996cd166010b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f696a1d6470d4582a6666eee7307759c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1e5cbd6cef84a55b4e07a26c21d552c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7ef8502621945749bec744d6a85f9e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}