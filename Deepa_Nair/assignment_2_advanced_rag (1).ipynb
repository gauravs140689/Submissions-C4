{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQy9pWzOTtZ6"
      },
      "source": [
        "# Assignment 2: Advanced RAG Techniques\n",
        "## Day 6 Session 2 - Advanced RAG Fundamentals\n",
        "\n",
        "**OBJECTIVE:** Implement advanced RAG techniques including postprocessors, response synthesizers, and structured outputs.\n",
        "\n",
        "**LEARNING GOALS:**\n",
        "- Understand and implement node postprocessors for filtering and reranking\n",
        "- Learn different response synthesis strategies (TreeSummarize, Refine)\n",
        "- Create structured outputs using Pydantic models\n",
        "- Build advanced retrieval pipelines with multiple processing stages\n",
        "\n",
        "**DATASET:** Use the same data folder as Assignment 1 (`Day_6/session_2/data/`)\n",
        "\n",
        "**PREREQUISITES:** Complete Assignment 1 first\n",
        "\n",
        "**INSTRUCTIONS:**\n",
        "1. Complete each function by replacing the TODO comments with actual implementation\n",
        "2. Run each cell after completing the function to test it\n",
        "3. The answers can be found in the `03_advanced_rag_techniques.ipynb` notebook\n",
        "4. Each technique builds on the previous one\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37UkqRYgTz3K",
        "outputId": "14f36d8f-7b1a-4320-edcb-fa9e60f99b4c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -r \"/content/drive/MyDrive/outskill_c4/requirements.txt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Lkf6OezT0JQ",
        "outputId": "de2f8f46-44b0-4c67-a8e6-26f84b414605"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m182.0/182.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: huggingface-hub 1.3.7 does not provide the extra 'inference'\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.2/47.2 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m278.0/278.0 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m303.3/303.3 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.3/188.3 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.6/57.6 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m109.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.8/96.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m329.1/329.1 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# securely input your key\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = getpass(\"Enter your OpenRouter key\")\n",
        "print(\"âœ“ OpenRouter key set successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TD9cMDTKY9Rb",
        "outputId": "68e4cb21-61bf-4278-e1e5-e20d7f030e4c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your OpenRouter keyÂ·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "âœ“ OpenRouter key set successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lW-rzXimTtZ7",
        "outputId": "299e726d-bfa8-4838-fac0-1c4540887f1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Advanced RAG libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries for advanced RAG\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Any\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# Core LlamaIndex components\n",
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext, Settings\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "\n",
        "# Vector store\n",
        "from llama_index.vector_stores.lancedb import LanceDBVectorStore\n",
        "\n",
        "# Embeddings and LLM\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.llms.openrouter import OpenRouter\n",
        "\n",
        "# Advanced RAG components (we'll use these in the assignments)\n",
        "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
        "from llama_index.core.response_synthesizers import TreeSummarize, Refine, CompactAndRefine\n",
        "from llama_index.core.output_parsers import PydanticOutputParser\n",
        "\n",
        "print(\"âœ… Advanced RAG libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257,
          "referenced_widgets": [
            "0a24da9b3e87487291e3f667ad879f71",
            "0769fa334e424a70b6a8c40362c649f6",
            "4ab8a2a5cacb4828be0088fde27f01e7",
            "78e1fa2e536149e08b860eae47aaef75",
            "b2f20b098b2746758202a50ad49fa1e1",
            "fda05d0a52fe49e5b82c2598d2bb971e",
            "7144f69470594c2784d065779bda7743",
            "527f06529b5d4ca9bd8507e7dd9c9398",
            "6a35c83d767a4039ad287b04aa873cce",
            "a4ef3214c2a94cf78a70473fcd8a46ce",
            "fdd06cc0c60f4277acdc2b3c2800b5bf"
          ]
        },
        "id": "ZCwmKpcxTtZ8",
        "outputId": "bb2b76d5-bda2-4b02-8342-4de0cd759764"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… OPENROUTER_API_KEY found - full advanced RAG functionality available\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a24da9b3e87487291e3f667ad879f71"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertModel LOAD REPORT from: BAAI/bge-small-en-v1.5\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Advanced RAG settings configured\n",
            "   - Chunk size: 512 (optimized for precision)\n",
            "   - Using local embeddings for cost efficiency\n",
            "   - OpenRouter LLM ready for response synthesis\n"
          ]
        }
      ],
      "source": [
        "def setup_advanced_rag_settings():\n",
        "    \"\"\"\n",
        "    Configure LlamaIndex with optimized settings for advanced RAG.\n",
        "    Uses local embeddings and OpenRouter for LLM operations.\n",
        "    \"\"\"\n",
        "    # Check for OpenRouter API key\n",
        "    api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "    if not api_key:\n",
        "        print(\"âš ï¸  OPENROUTER_API_KEY not found - LLM operations will be limited\")\n",
        "        print(\"   You can still complete postprocessor and retrieval exercises\")\n",
        "    else:\n",
        "        print(\"âœ… OPENROUTER_API_KEY found - full advanced RAG functionality available\")\n",
        "\n",
        "        # Configure OpenRouter LLM\n",
        "        Settings.llm = OpenRouter(\n",
        "            api_key=api_key,\n",
        "            model=\"gpt-4o\",\n",
        "            temperature=0.1  # Lower temperature for more consistent responses\n",
        "        )\n",
        "\n",
        "    # Configure local embeddings (no API key required)\n",
        "    Settings.embed_model = HuggingFaceEmbedding(\n",
        "        model_name=\"BAAI/bge-small-en-v1.5\",\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "\n",
        "    # Advanced RAG configuration\n",
        "    Settings.chunk_size = 512  # Smaller chunks for better precision\n",
        "    Settings.chunk_overlap = 50\n",
        "\n",
        "    print(\"âœ… Advanced RAG settings configured\")\n",
        "    print(\"   - Chunk size: 512 (optimized for precision)\")\n",
        "    print(\"   - Using local embeddings for cost efficiency\")\n",
        "    print(\"   - OpenRouter LLM ready for response synthesis\")\n",
        "\n",
        "# Setup the configuration\n",
        "setup_advanced_rag_settings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150,
          "referenced_widgets": [
            "ecb32c7cf65b4c869b448111e54e4b7b",
            "96882c32ae384cad82e3d2e0f9fdaff0",
            "d1e8a702dea943c2b77d1332a2b97884",
            "1f95c2b4bcbd4bc3a7648ede435b6fd1",
            "cd2feabbcbb24a9f8368f919779d77d8",
            "6d8a494da3384c709b42517c3e5fc7f2",
            "295688b970314ba88dae222671e13356",
            "869dc817e20249c4b6912797f1688526",
            "41487a38dfd747acaf98b2ab70b8bb10",
            "e741f5c0a5624c548f58f652b61464e0",
            "e659c7cd13db4eb09fc7f935a2c3eb5b",
            "9260430b81674a6ca7c7d9651bcd284f",
            "08a8198ebfe540e0ac913958e9187409",
            "e339c4d518b74ba389b2e7b2555e8ed9",
            "b07f5952ad934211a29c649b8daba620",
            "b5b0820deb9a463892095b693daed3da",
            "054bf2ee13ef4f3ab5c66205e8426f2f",
            "4f2e0e21aa1c41b6bc46e04cf2576aa2",
            "1373f6e8fca4467e88872a8d24fe63b2",
            "11d5e3a6182c43fca936d1a59742f232",
            "67452e0c30474c0da9712e10054f3e5c",
            "55b530a4c14c460c8dac499709c3e8c9"
          ]
        },
        "id": "HNGI2niLTtZ9",
        "outputId": "850571e8-9191-47e5-beaa-3a9907f2e2c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“ Setting up basic index for advanced RAG...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parsing nodes:   0%|          | 0/23 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ecb32c7cf65b4c869b448111e54e4b7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating embeddings:   0%|          | 0/66 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9260430b81674a6ca7c7d9651bcd284f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Basic index created with 23 documents\n",
            "   Ready for advanced RAG techniques!\n",
            "ğŸš€ Ready to implement advanced RAG techniques!\n"
          ]
        }
      ],
      "source": [
        "# Setup: Create index from Assignment 1 (reuse the basic functionality)\n",
        "def setup_basic_index(data_folder: str = \"/content/drive/MyDrive/outskill_c4/data/\", force_rebuild: bool = False):\n",
        "    \"\"\"\n",
        "    Create a basic vector index that we'll enhance with advanced techniques.\n",
        "    This reuses the concepts from Assignment 1.\n",
        "    \"\"\"\n",
        "    # Create vector store\n",
        "    vector_store = LanceDBVectorStore(\n",
        "        uri=\"./advanced_rag_vectordb\",\n",
        "        table_name=\"documents\"\n",
        "    )\n",
        "\n",
        "    # Load documents\n",
        "    if not Path(data_folder).exists():\n",
        "        print(f\"âŒ Data folder not found: {data_folder}\")\n",
        "        return None\n",
        "\n",
        "    reader = SimpleDirectoryReader(input_dir=data_folder, recursive=True)\n",
        "    documents = reader.load_data()\n",
        "\n",
        "    # Create storage context and index\n",
        "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "    index = VectorStoreIndex.from_documents(\n",
        "        documents,\n",
        "        storage_context=storage_context,\n",
        "        show_progress=True\n",
        "    )\n",
        "\n",
        "    print(f\"âœ… Basic index created with {len(documents)} documents\")\n",
        "    print(\"   Ready for advanced RAG techniques!\")\n",
        "    return index\n",
        "\n",
        "# Create the basic index\n",
        "print(\"ğŸ“ Setting up basic index for advanced RAG...\")\n",
        "index = setup_basic_index()\n",
        "\n",
        "if index:\n",
        "    print(\"ğŸš€ Ready to implement advanced RAG techniques!\")\n",
        "else:\n",
        "    print(\"âŒ Failed to create index - check data folder path\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiXmi9WRTtZ9"
      },
      "source": [
        "## 1. Node Postprocessors - Similarity Filtering\n",
        "\n",
        "**Concept:** Postprocessors refine retrieval results after the initial vector search. The `SimilarityPostprocessor` filters out chunks that fall below a relevance threshold.\n",
        "\n",
        "**Why it matters:** Raw vector search often returns some irrelevant results. Filtering improves precision and response quality.\n",
        "\n",
        "Complete the function below to create a query engine with similarity filtering.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDwfaMJyTtZ9",
        "outputId": "ff9f3572-c927-43e3-adfe-030cede860c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Query engine with similarity filtering created\n",
            "\n",
            "ğŸ” Testing query: 'What are the benefits of AI agents?'\n",
            "   (Complete the function above to test the response)\n"
          ]
        }
      ],
      "source": [
        "def create_query_engine_with_similarity_filter(index, similarity_cutoff: float = 0.3, top_k: int = 10):\n",
        "    \"\"\"\n",
        "    Create a query engine that filters results based on similarity scores.\n",
        "\n",
        "    TODO: Complete this function to create a query engine with similarity postprocessing.\n",
        "    HINT: Use index.as_query_engine() with node_postprocessors parameter containing SimilarityPostprocessor\n",
        "\n",
        "    Args:\n",
        "        index: Vector index to query\n",
        "        similarity_cutoff: Minimum similarity score (0.0 to 1.0)\n",
        "        top_k: Number of initial results to retrieve before filtering\n",
        "\n",
        "    Returns:\n",
        "        Query engine with similarity filtering\n",
        "    \"\"\"\n",
        "    # TODO: Create similarity postprocessor with the cutoff threshold\n",
        "    similarity_processor = SimilarityPostprocessor(similarity_cutoff=similarity_cutoff)\n",
        "\n",
        "    # TODO: Create query engine with similarity filtering\n",
        "    query_engine = index.as_query_engine(similarity_top_k=top_k, node_postprocessors= [similarity_processor])\n",
        "    return query_engine\n",
        "\n",
        "    # PLACEHOLDER - Replace with actual implementation\n",
        "    print(f\"TODO: Create query engine with similarity cutoff {similarity_cutoff}\")\n",
        "    return None\n",
        "\n",
        "# Test the function\n",
        "if index:\n",
        "    filtered_engine = create_query_engine_with_similarity_filter(index, similarity_cutoff=0.3)\n",
        "\n",
        "    if filtered_engine:\n",
        "        print(\"âœ… Query engine with similarity filtering created\")\n",
        "\n",
        "        # Test query\n",
        "        test_query = \"What are the benefits of AI agents?\"\n",
        "        print(f\"\\nğŸ” Testing query: '{test_query}'\")\n",
        "\n",
        "        # Uncomment when implemented:\n",
        "        # response = filtered_engine.query(test_query)\n",
        "        # print(f\"ğŸ“ Response: {response}\")\n",
        "        print(\"   (Complete the function above to test the response)\")\n",
        "    else:\n",
        "        print(\"âŒ Failed to create filtered query engine\")\n",
        "else:\n",
        "    print(\"âŒ No index available - run previous cells first\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtoJteG8TtZ9"
      },
      "source": [
        "## 2. Response Synthesizers - TreeSummarize\n",
        "\n",
        "**Concept:** Response synthesizers control how retrieved information becomes final answers. `TreeSummarize` builds responses hierarchically, ideal for complex analytical questions.\n",
        "\n",
        "**Why it matters:** Different synthesis strategies work better for different query types. TreeSummarize excels at comprehensive analysis and long-form responses.\n",
        "\n",
        "Complete the function below to create a query engine with TreeSummarize response synthesis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33cPwxLWTtZ9",
        "outputId": "a47f9c9e-b8fb-4080-a9c5-f5654e5b80d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Query engine with TreeSummarize created\n",
            "\n",
            "ğŸ” Testing analytical query: 'Compare the advantages and disadvantages of different AI agent frameworks'\n",
            "   (Complete the function above to test comprehensive analysis)\n"
          ]
        }
      ],
      "source": [
        "def create_query_engine_with_tree_summarize(index, top_k: int = 5):\n",
        "    \"\"\"\n",
        "    Create a query engine that uses TreeSummarize for comprehensive responses.\n",
        "\n",
        "    TODO: Complete this function to create a query engine with TreeSummarize synthesis.\n",
        "    HINT: Create a TreeSummarize instance, then use index.as_query_engine() with response_synthesizer parameter\n",
        "\n",
        "    Args:\n",
        "        index: Vector index to query\n",
        "        top_k: Number of results to retrieve\n",
        "\n",
        "    Returns:\n",
        "        Query engine with TreeSummarize synthesis\n",
        "    \"\"\"\n",
        "    # TODO: Create TreeSummarize response synthesizer\n",
        "    tree_synthesizer = TreeSummarize()\n",
        "\n",
        "    # TODO: Create query engine with the synthesizer\n",
        "    query_engine = index.as_query_engine(similarity_top_k=top_k, response_synthesizer=tree_synthesizer)\n",
        "\n",
        "    return query_engine\n",
        "\n",
        "    # PLACEHOLDER - Replace with actual implementation\n",
        "    print(f\"TODO: Create query engine with TreeSummarize synthesis\")\n",
        "    return None\n",
        "\n",
        "# Test the function\n",
        "if index:\n",
        "    tree_engine = create_query_engine_with_tree_summarize(index)\n",
        "\n",
        "    if tree_engine:\n",
        "        print(\"âœ… Query engine with TreeSummarize created\")\n",
        "\n",
        "        # Test with a complex analytical query\n",
        "        analytical_query = \"Compare the advantages and disadvantages of different AI agent frameworks\"\n",
        "        print(f\"\\nğŸ” Testing analytical query: '{analytical_query}'\")\n",
        "\n",
        "        # Uncomment when implemented:\n",
        "        # response = tree_engine.query(analytical_query)\n",
        "        # print(f\"ğŸ“ TreeSummarize Response:\\n{response}\")\n",
        "        print(\"   (Complete the function above to test comprehensive analysis)\")\n",
        "    else:\n",
        "        print(\"âŒ Failed to create TreeSummarize query engine\")\n",
        "else:\n",
        "    print(\"âŒ No index available - run previous cells first\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LI2lBMPTtZ-"
      },
      "source": [
        "## 3. Structured Outputs with Pydantic Models\n",
        "\n",
        "**Concept:** Structured outputs ensure predictable, parseable responses using Pydantic models. This is essential for API endpoints and data pipelines.\n",
        "\n",
        "**Why it matters:** Instead of free-text responses, you get type-safe, validated data structures that applications can reliably process.\n",
        "\n",
        "Complete the function below to create a structured output system for extracting research paper information.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIvuuLXeTtZ-",
        "outputId": "9eb920f9-7dff-4484-d9e8-5e529fdb376b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Structured output program created\n",
            "\n",
            "ğŸ” Testing structured query: 'Tell me about AI agents and their capabilities'\n",
            "   (Complete the function above to get structured JSON output)\n",
            "\n",
            "ğŸ’¡ Expected output format:\n",
            "   - title: String\n",
            "   - key_points: List of strings\n",
            "   - applications: List of strings\n",
            "   - summary: String\n"
          ]
        }
      ],
      "source": [
        "# First, define the Pydantic models for structured outputs\n",
        "class ResearchPaperInfo(BaseModel):\n",
        "    \"\"\"Structured information about a research paper or AI concept.\"\"\"\n",
        "    title: str = Field(description=\"The main title or concept name\")\n",
        "    key_points: List[str] = Field(description=\"3-5 main points or findings\")\n",
        "    applications: List[str] = Field(description=\"Practical applications or use cases\")\n",
        "    summary: str = Field(description=\"Brief 2-3 sentence summary\")\n",
        "\n",
        "# Import the missing component\n",
        "from llama_index.core.program import LLMTextCompletionProgram\n",
        "\n",
        "def create_structured_output_program(output_model: BaseModel = ResearchPaperInfo):\n",
        "    \"\"\"\n",
        "    Create a structured output program using Pydantic models.\n",
        "\n",
        "    TODO: Complete this function to create a structured output program.\n",
        "    HINT: Use LLMTextCompletionProgram.from_defaults() with PydanticOutputParser and a prompt template\n",
        "\n",
        "    Args:\n",
        "        output_model: Pydantic model class for structured output\n",
        "\n",
        "    Returns:\n",
        "        LLMTextCompletionProgram that returns structured data\n",
        "    \"\"\"\n",
        "    # TODO: Create output parser with the Pydantic model\n",
        "    output_parser = PydanticOutputParser(output_cls=output_model)\n",
        "\n",
        "    # Define a prompt template for the LLM\n",
        "    prompt_template = \"\"\"\n",
        "Extract information from the provided context that answers the query.\n",
        "Format the response strictly as a JSON object according to the following Pydantic model:\n",
        "{schema_str}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Query: {query}\n",
        "JSON Response:\n",
        "\"\"\"\n",
        "\n",
        "    # TODO: Create the structured output program with the output parser and prompt template\n",
        "    program = LLMTextCompletionProgram.from_defaults(\n",
        "        output_parser=output_parser,\n",
        "        prompt_template_str=prompt_template\n",
        "    )\n",
        "    return program\n",
        "\n",
        "    # PLACEHOLDER - Replace with actual implementation\n",
        "    print(f\"TODO: Create structured output program with {output_model.__name__}\")\n",
        "    return None\n",
        "\n",
        "# Test the function\n",
        "if index:\n",
        "    structured_program = create_structured_output_program(ResearchPaperInfo)\n",
        "\n",
        "    if structured_program:\n",
        "        print(\"âœ… Structured output program created\")\n",
        "\n",
        "        # Test with retrieval and structured extraction\n",
        "        structure_query = \"Tell me about AI agents and their capabilities\"\n",
        "        print(f\"\\nğŸ” Testing structured query: '{structure_query}'\")\n",
        "\n",
        "        # Get context for structured extraction (Uncomment when implemented)\n",
        "        # retriever = VectorIndexRetriever(index=index, similarity_top_k=3)\n",
        "        # nodes = retriever.retrieve(structure_query)\n",
        "        # context = \"\\n\".join([node.text for node in nodes])\n",
        "\n",
        "        # Uncomment when implemented:\n",
        "        # response = structured_program(context=context, query=structure_query)\n",
        "        # print(f\"ğŸ“Š Structured Response:\\n{response}\")\n",
        "        print(\"   (Complete the function above to get structured JSON output)\")\n",
        "\n",
        "        print(\"\\nğŸ’¡ Expected output format:\")\n",
        "        print(\"   - title: String\")\n",
        "        print(\"   - key_points: List of strings\")\n",
        "        print(\"   - applications: List of strings\")\n",
        "        print(\"   - summary: String\")\n",
        "    else:\n",
        "        print(\"âŒ Failed to create structured output program\")\n",
        "else:\n",
        "    print(\"âŒ No index available - run previous cells first\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAFoVKvITtZ-"
      },
      "source": [
        "## 4. Advanced Pipeline - Combining All Techniques\n",
        "\n",
        "**Concept:** Combine multiple advanced techniques into a single powerful query engine: similarity filtering + response synthesis + structured output.\n",
        "\n",
        "**Why it matters:** Production RAG systems often need multiple techniques working together for optimal results.\n",
        "\n",
        "Complete the function below to create a comprehensive advanced RAG pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kfuTQs5TtZ-",
        "outputId": "ea0d7ae4-8827-41ea-fb71-b5787209512c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Advanced RAG pipeline created successfully!\n",
            "   ğŸ”§ Similarity filtering: âœ…\n",
            "   ğŸŒ³ TreeSummarize synthesis: âœ…\n",
            "\n",
            "ğŸ” Testing complex query: 'Analyze the current state and future potential of AI agent technologies'\n",
            "   (Complete the function above to test the full pipeline)\n",
            "\n",
            "ğŸ¯ This should provide:\n",
            "   - Filtered relevant results only\n",
            "   - Comprehensive analytical response\n",
            "   - Combined postprocessing and synthesis\n"
          ]
        }
      ],
      "source": [
        "def create_advanced_rag_pipeline(index, similarity_cutoff: float = 0.3, top_k: int = 10):\n",
        "    \"\"\"\n",
        "    Create a comprehensive advanced RAG pipeline combining multiple techniques.\n",
        "\n",
        "    TODO: Complete this function to create the ultimate advanced RAG query engine.\n",
        "    HINT: Combine SimilarityPostprocessor + TreeSummarize using index.as_query_engine()\n",
        "\n",
        "    Args:\n",
        "        index: Vector index to query\n",
        "        similarity_cutoff: Minimum similarity score for filtering\n",
        "        top_k: Number of initial results to retrieve\n",
        "\n",
        "    Returns:\n",
        "        Advanced query engine with filtering and synthesis combined\n",
        "    \"\"\"\n",
        "    # TODO: Create similarity postprocessor\n",
        "    similarity_processor = SimilarityPostprocessor(similarity_cutoff=similarity_cutoff)\n",
        "\n",
        "    # TODO: Create TreeSummarize for comprehensive responses\n",
        "    tree_synthesizer = TreeSummarize()\n",
        "\n",
        "    # TODO: Create the comprehensive query engine combining both techniques\n",
        "    advanced_engine = index.as_query_engine(\n",
        "        similarity_top_k=top_k,\n",
        "        node_postprocessors=[similarity_processor],\n",
        "        response_synthesizer=tree_synthesizer\n",
        "    )\n",
        "\n",
        "    return advanced_engine\n",
        "\n",
        "    # PLACEHOLDER - Replace with actual implementation\n",
        "    print(f\"TODO: Create advanced RAG pipeline with all techniques\")\n",
        "    return None\n",
        "\n",
        "# Test the comprehensive pipeline\n",
        "if index:\n",
        "    advanced_pipeline = create_advanced_rag_pipeline(index)\n",
        "\n",
        "    if advanced_pipeline:\n",
        "        print(\"âœ… Advanced RAG pipeline created successfully!\")\n",
        "        print(\"   ğŸ”§ Similarity filtering: âœ…\")\n",
        "        print(\"   ğŸŒ³ TreeSummarize synthesis: âœ…\")\n",
        "\n",
        "        # Test with complex query\n",
        "        complex_query = \"Analyze the current state and future potential of AI agent technologies\"\n",
        "        print(f\"\\nğŸ” Testing complex query: '{complex_query}'\")\n",
        "\n",
        "        # Uncomment when implemented:\n",
        "        # response = advanced_pipeline.query(complex_query)\n",
        "        # print(f\"ğŸš€ Advanced RAG Response:\\n{response}\")\n",
        "        print(\"   (Complete the function above to test the full pipeline)\")\n",
        "\n",
        "        print(\"\\nğŸ¯ This should provide:\")\n",
        "        print(\"   - Filtered relevant results only\")\n",
        "        print(\"   - Comprehensive analytical response\")\n",
        "        print(\"   - Combined postprocessing and synthesis\")\n",
        "    else:\n",
        "        print(\"âŒ Failed to create advanced RAG pipeline\")\n",
        "else:\n",
        "    print(\"âŒ No index available - run previous cells first\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fj1N1dtjTtZ-"
      },
      "source": [
        "## 5. Final Test - Compare Basic vs Advanced RAG\n",
        "\n",
        "Once you've completed all the functions above, run this cell to compare basic RAG with your advanced techniques.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oUODPe7TtZ-",
        "outputId": "be1c690b-3d3e-4cc7-de40-ef98c02e6d38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Advanced RAG Techniques Assignment - Final Test\n",
            "============================================================\n",
            "\n",
            "ğŸ“Š Component Status:\n",
            "   âœ… Basic Index\n",
            "   âœ… Similarity Filter\n",
            "   âœ… TreeSummarize\n",
            "   âœ… Structured Output\n",
            "   âœ… Advanced Pipeline\n",
            "\n",
            "ğŸ” Creating basic query engine for comparison...\n",
            "\n",
            "============================================================\n",
            "ğŸ†š COMPARISON: Basic vs Advanced RAG\n",
            "============================================================\n",
            "\n",
            "ğŸ“‹ Test Query 1: 'What are the key capabilities of AI agents?'\n",
            "--------------------------------------------------\n",
            "ğŸ”¹ Basic RAG:\n",
            "   (Standard vector search + simple response)\n",
            "\n",
            "ğŸ”¸ Advanced RAG:\n",
            "   (Filtered + TreeSummarize + Structured output)\n",
            "\n",
            "ğŸ“‹ Test Query 2: 'How do you evaluate agent performance metrics?'\n",
            "--------------------------------------------------\n",
            "ğŸ”¹ Basic RAG:\n",
            "   (Standard vector search + simple response)\n",
            "\n",
            "ğŸ”¸ Advanced RAG:\n",
            "   (Filtered + TreeSummarize + Structured output)\n",
            "\n",
            "ğŸ“‹ Test Query 3: 'Explain the benefits and challenges of multimodal AI systems'\n",
            "--------------------------------------------------\n",
            "ğŸ”¹ Basic RAG:\n",
            "   (Standard vector search + simple response)\n",
            "\n",
            "ğŸ”¸ Advanced RAG:\n",
            "   (Filtered + TreeSummarize + Structured output)\n",
            "\n",
            "============================================================\n",
            "ğŸ¯ Assignment Status:\n",
            "   Completed: 5/5 components\n",
            "\n",
            "ğŸ‰ Congratulations! You've mastered Advanced RAG Techniques!\n",
            "   âœ… Node postprocessors for result filtering\n",
            "   âœ… Response synthesizers for better answers\n",
            "   âœ… Structured outputs for reliable data\n",
            "   âœ… Advanced pipelines combining all techniques\n",
            "\n",
            "ğŸš€ You're ready for production RAG systems!\n",
            "\n",
            "ğŸ’¡ Key learnings:\n",
            "   - Postprocessors improve result relevance and precision\n",
            "   - Different synthesizers work better for different query types\n",
            "   - Structured outputs enable reliable system integration\n",
            "   - Advanced techniques can be combined for production systems\n"
          ]
        }
      ],
      "source": [
        "# Final comparison: Basic vs Advanced RAG\n",
        "print(\"ğŸš€ Advanced RAG Techniques Assignment - Final Test\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Test queries for comparison\n",
        "test_queries = [\n",
        "    \"What are the key capabilities of AI agents?\",\n",
        "    \"How do you evaluate agent performance metrics?\",\n",
        "    \"Explain the benefits and challenges of multimodal AI systems\"\n",
        "]\n",
        "\n",
        "# Check if all components were created\n",
        "components_status = {\n",
        "    \"Basic Index\": index is not None,\n",
        "    \"Similarity Filter\": 'filtered_engine' in locals() and filtered_engine is not None,\n",
        "    \"TreeSummarize\": 'tree_engine' in locals() and tree_engine is not None,\n",
        "    \"Structured Output\": 'structured_program' in locals() and structured_program is not None,\n",
        "    \"Advanced Pipeline\": 'advanced_pipeline' in locals() and advanced_pipeline is not None\n",
        "}\n",
        "\n",
        "print(\"\\nğŸ“Š Component Status:\")\n",
        "for component, status in components_status.items():\n",
        "    status_icon = \"âœ…\" if status else \"âŒ\"\n",
        "    print(f\"   {status_icon} {component}\")\n",
        "\n",
        "# Create basic query engine for comparison\n",
        "if index:\n",
        "    print(\"\\nğŸ” Creating basic query engine for comparison...\")\n",
        "    basic_engine = index.as_query_engine(similarity_top_k=5)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"ğŸ†š COMPARISON: Basic vs Advanced RAG\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for i, query in enumerate(test_queries, 1):\n",
        "        print(f\"\\nğŸ“‹ Test Query {i}: '{query}'\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        # Basic RAG\n",
        "        print(\"ğŸ”¹ Basic RAG:\")\n",
        "        if basic_engine:\n",
        "            # Uncomment when testing:\n",
        "            # basic_response = basic_engine.query(query)\n",
        "            # print(f\"   Response: {str(basic_response)[:200]}...\")\n",
        "            print(\"   (Standard vector search + simple response)\")\n",
        "\n",
        "        # Advanced RAG (if implemented)\n",
        "        print(\"\\nğŸ”¸ Advanced RAG:\")\n",
        "        if components_status[\"Advanced Pipeline\"]:\n",
        "            # Uncomment when testing:\n",
        "            # advanced_response = advanced_pipeline.query(query)\n",
        "            # print(f\"   Response: {advanced_response}\")\n",
        "            print(\"   (Filtered + TreeSummarize + Structured output)\")\n",
        "        else:\n",
        "            print(\"   Complete the advanced pipeline function to test\")\n",
        "\n",
        "# Final status\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ğŸ¯ Assignment Status:\")\n",
        "completed_count = sum(components_status.values())\n",
        "total_count = len(components_status)\n",
        "\n",
        "print(f\"   Completed: {completed_count}/{total_count} components\")\n",
        "\n",
        "if completed_count == total_count:\n",
        "    print(\"\\nğŸ‰ Congratulations! You've mastered Advanced RAG Techniques!\")\n",
        "    print(\"   âœ… Node postprocessors for result filtering\")\n",
        "    print(\"   âœ… Response synthesizers for better answers\")\n",
        "    print(\"   âœ… Structured outputs for reliable data\")\n",
        "    print(\"   âœ… Advanced pipelines combining all techniques\")\n",
        "    print(\"\\nğŸš€ You're ready for production RAG systems!\")\n",
        "else:\n",
        "    missing = total_count - completed_count\n",
        "    print(f\"\\nğŸ“ Complete {missing} more components to finish the assignment:\")\n",
        "    for component, status in components_status.items():\n",
        "        if not status:\n",
        "            print(f\"   - {component}\")\n",
        "\n",
        "print(\"\\nğŸ’¡ Key learnings:\")\n",
        "print(\"   - Postprocessors improve result relevance and precision\")\n",
        "print(\"   - Different synthesizers work better for different query types\")\n",
        "print(\"   - Structured outputs enable reliable system integration\")\n",
        "print(\"   - Advanced techniques can be combined for production systems\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "accelerator",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a24da9b3e87487291e3f667ad879f71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0769fa334e424a70b6a8c40362c649f6",
              "IPY_MODEL_4ab8a2a5cacb4828be0088fde27f01e7",
              "IPY_MODEL_78e1fa2e536149e08b860eae47aaef75"
            ],
            "layout": "IPY_MODEL_b2f20b098b2746758202a50ad49fa1e1"
          }
        },
        "0769fa334e424a70b6a8c40362c649f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fda05d0a52fe49e5b82c2598d2bb971e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7144f69470594c2784d065779bda7743",
            "value": "Loadingâ€‡weights:â€‡100%"
          }
        },
        "4ab8a2a5cacb4828be0088fde27f01e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_527f06529b5d4ca9bd8507e7dd9c9398",
            "max": 199,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a35c83d767a4039ad287b04aa873cce",
            "value": 199
          }
        },
        "78e1fa2e536149e08b860eae47aaef75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4ef3214c2a94cf78a70473fcd8a46ce",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_fdd06cc0c60f4277acdc2b3c2800b5bf",
            "value": "â€‡199/199â€‡[00:00&lt;00:00,â€‡504.87it/s,â€‡Materializingâ€‡param=pooler.dense.weight]"
          }
        },
        "b2f20b098b2746758202a50ad49fa1e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fda05d0a52fe49e5b82c2598d2bb971e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7144f69470594c2784d065779bda7743": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "527f06529b5d4ca9bd8507e7dd9c9398": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a35c83d767a4039ad287b04aa873cce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4ef3214c2a94cf78a70473fcd8a46ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdd06cc0c60f4277acdc2b3c2800b5bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecb32c7cf65b4c869b448111e54e4b7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96882c32ae384cad82e3d2e0f9fdaff0",
              "IPY_MODEL_d1e8a702dea943c2b77d1332a2b97884",
              "IPY_MODEL_1f95c2b4bcbd4bc3a7648ede435b6fd1"
            ],
            "layout": "IPY_MODEL_cd2feabbcbb24a9f8368f919779d77d8"
          }
        },
        "96882c32ae384cad82e3d2e0f9fdaff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d8a494da3384c709b42517c3e5fc7f2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_295688b970314ba88dae222671e13356",
            "value": "Parsingâ€‡nodes:â€‡100%"
          }
        },
        "d1e8a702dea943c2b77d1332a2b97884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_869dc817e20249c4b6912797f1688526",
            "max": 23,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41487a38dfd747acaf98b2ab70b8bb10",
            "value": 23
          }
        },
        "1f95c2b4bcbd4bc3a7648ede435b6fd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e741f5c0a5624c548f58f652b61464e0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_e659c7cd13db4eb09fc7f935a2c3eb5b",
            "value": "â€‡23/23â€‡[00:00&lt;00:00,â€‡62.37it/s]"
          }
        },
        "cd2feabbcbb24a9f8368f919779d77d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d8a494da3384c709b42517c3e5fc7f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "295688b970314ba88dae222671e13356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "869dc817e20249c4b6912797f1688526": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41487a38dfd747acaf98b2ab70b8bb10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e741f5c0a5624c548f58f652b61464e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e659c7cd13db4eb09fc7f935a2c3eb5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9260430b81674a6ca7c7d9651bcd284f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08a8198ebfe540e0ac913958e9187409",
              "IPY_MODEL_e339c4d518b74ba389b2e7b2555e8ed9",
              "IPY_MODEL_b07f5952ad934211a29c649b8daba620"
            ],
            "layout": "IPY_MODEL_b5b0820deb9a463892095b693daed3da"
          }
        },
        "08a8198ebfe540e0ac913958e9187409": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_054bf2ee13ef4f3ab5c66205e8426f2f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4f2e0e21aa1c41b6bc46e04cf2576aa2",
            "value": "Generatingâ€‡embeddings:â€‡100%"
          }
        },
        "e339c4d518b74ba389b2e7b2555e8ed9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1373f6e8fca4467e88872a8d24fe63b2",
            "max": 66,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11d5e3a6182c43fca936d1a59742f232",
            "value": 66
          }
        },
        "b07f5952ad934211a29c649b8daba620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67452e0c30474c0da9712e10054f3e5c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_55b530a4c14c460c8dac499709c3e8c9",
            "value": "â€‡66/66â€‡[00:36&lt;00:00,â€‡â€‡1.86it/s]"
          }
        },
        "b5b0820deb9a463892095b693daed3da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "054bf2ee13ef4f3ab5c66205e8426f2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f2e0e21aa1c41b6bc46e04cf2576aa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1373f6e8fca4467e88872a8d24fe63b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11d5e3a6182c43fca936d1a59742f232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67452e0c30474c0da9712e10054f3e5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55b530a4c14c460c8dac499709c3e8c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}