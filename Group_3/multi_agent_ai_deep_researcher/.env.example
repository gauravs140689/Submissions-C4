# ============================================================================
# Multi-Agent AI Deep Researcher - Environment Configuration
# ============================================================================
# Copy this file to .env and adjust values for your environment.
# This file is used for LOCAL DEVELOPMENT ONLY.
# For production, set environment variables directly on your deployment platform.
# ============================================================================

# ============================================================================
# OLLAMA LLM CONFIGURATION
# ============================================================================
# Ollama should be running locally. Start with: ollama serve
# Available models: mistral, neural-chat, llama2, dolphin-mixtral, etc.

OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=mistral
OLLAMA_TIMEOUT=300

# ============================================================================
# TAVILY WEB SEARCH CONFIGURATION
# ============================================================================
# Get API key from https://tavily.com/

TAVILY_API_KEY=your_api_key_here

# ============================================================================
# FAISS VECTOR STORE CONFIGURATION
# ============================================================================
# Local path for storing FAISS index for semantic search

FAISS_INDEX_PATH=./data/faiss_index
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# ============================================================================
# CHECKPOINT & SESSION CONFIGURATION
# ============================================================================
# Controls persistence of research sessions and state

CHECKPOINT_PATH=./data/checkpoints
SESSION_MEMORY_TYPE=sqlite

# ============================================================================
# RESEARCH PIPELINE CONFIGURATION
# ============================================================================

MAX_SOURCES_DEFAULT=10
MAX_REFINEMENT_PASSES=3
CHUNK_SIZE=1000

# ============================================================================
# LOGGING CONFIGURATION
# ============================================================================
# LOG_LEVEL: DEBUG (verbose), INFO (normal), WARNING, ERROR
# LOG_FORMAT: json (structured) or text (human-readable)

LOG_LEVEL=INFO
LOG_FORMAT=json

# ============================================================================
# FEATURE FLAGS
# ============================================================================

ENABLE_SOURCE_TRACKING=true
ENABLE_STREAMING=true
DEBUG_MODE=false

# ============================================================================
# RETRY CONFIGURATION
# ============================================================================
# For resilient API calls to external services

MAX_RETRIES=3
RETRY_WAIT_SECONDS=1

# ============================================================================
# ENVIRONMENT TYPE
# ============================================================================
# development or production (affects error handling and logging verbosity)

ENVIRONMENT=development
