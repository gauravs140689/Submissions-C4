{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyNpJQP4SCV2"
      },
      "source": [
        "# Assignment 3b: Advanced Gradio RAG Frontend\n",
        "## Day 6 Session 2 - Building Configurable RAG Applications\n",
        "\n",
        "In this assignment, you'll extend your basic RAG interface with advanced configuration options to create a professional, feature-rich RAG application.\n",
        "\n",
        "**New Features to Add:**\n",
        "- Model selection dropdown (gpt-4o, gpt-4o-mini)\n",
        "- Temperature slider (0 to 1 with 0.1 intervals)\n",
        "- Chunk size configuration\n",
        "- Chunk overlap configuration  \n",
        "- Similarity top-k slider\n",
        "- Node postprocessor multiselect\n",
        "- Similarity cutoff slider\n",
        "- Response synthesizer multiselect\n",
        "\n",
        "**Learning Objectives:**\n",
        "- Advanced Gradio components and interactions\n",
        "- Dynamic RAG configuration\n",
        "- Professional UI design patterns\n",
        "- Parameter validation and handling\n",
        "- Building production-ready AI applications\n",
        "\n",
        "**Prerequisites:**\n",
        "- Completed Assignment 3a (Basic Gradio RAG)\n",
        "- Understanding of RAG parameters and their effects\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NxZZakjSCV4"
      },
      "source": [
        "## ðŸ“š Part 1: Setup and Imports\n",
        "\n",
        "Import all necessary libraries including advanced RAG components for configuration options.\n",
        "\n",
        "**Note:** This assignment uses OpenRouter for LLM access (not OpenAI). Make sure you have your `OPENROUTER_API_KEY` environment variable set.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dtt2x5USHBo",
        "outputId": "3e8343b9-fb15-4fde-831f-1ba9a73f2e97"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "z38Cts_ISGZh",
        "outputId": "090338aa-eb58-4f4e-d273-af15359bb670"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 1)) (4.13.5)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 2)) (2.29.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 3)) (2.188.0)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 4)) (2.47.0)\n",
            "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 5)) (0.3.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (5.50.0)\n",
            "Requirement already satisfied: gradio_client in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 7)) (1.14.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 8)) (1.3.7)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 9)) (6.17.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 10)) (7.34.0)\n",
            "Collecting lancedb (from -r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 11))\n",
            "  Downloading lancedb-0.29.2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting llama-index (from -r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_index-0.14.13-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting llama-index-vector-stores-lancedb (from -r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 13))\n",
            "  Downloading llama_index_vector_stores_lancedb-0.4.4-py3-none-any.whl.metadata (460 bytes)\n",
            "Collecting llama-index-embeddings-huggingface (from -r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 14))\n",
            "  Downloading llama_index_embeddings_huggingface-0.6.1-py3-none-any.whl.metadata (458 bytes)\n",
            "Collecting llama-index-llms-huggingface-api (from -r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 15))\n",
            "  Downloading llama_index_llms_huggingface_api-0.6.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting llama-index-embeddings-openai (from -r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 16))\n",
            "  Downloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl.metadata (400 bytes)\n",
            "Collecting llama-index-llms-openrouter (from -r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 17))\n",
            "  Downloading llama_index_llms_openrouter-0.4.4-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 18)) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 19)) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 20)) (2.2.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 21)) (2.16.0)\n",
            "Collecting openai-whisper (from -r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 22))\n",
            "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 23)) (2.12.3)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 24)) (5.2.2)\n",
            "Collecting yt-dlp (from -r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 25))\n",
            "  Downloading yt_dlp-2026.2.4-py3-none-any.whl.metadata (182 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m182.0/182.0 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 26)) (3.8.11)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 1)) (2.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 2)) (1.72.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 2)) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 2)) (1.27.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 2)) (2.32.4)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 3)) (0.31.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 3)) (4.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 4)) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 4)) (4.9.1)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (4.12.1)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (0.123.10)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (1.0.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (3.0.3)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (3.11.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (26.0)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (11.3.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (0.0.22)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (6.0.3)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (0.14.14)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (0.1.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (0.50.0)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (0.21.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (0.40.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio_client->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 7)) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=13.0 in /usr/local/lib/python3.12/dist-packages (from gradio_client->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 7)) (15.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 8)) (3.20.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 8)) (1.2.0)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 8)) (1.5.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 8)) (4.67.2)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 8)) (0.21.1)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 9)) (1.8.15)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 9)) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 9)) (0.2.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 9)) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 9)) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 9)) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 9)) (6.5.1)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 9)) (5.7.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 10)) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 10))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 10)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 10)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 10)) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 10)) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 10)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 10)) (4.9.0)\n",
            "Requirement already satisfied: deprecation in /usr/local/lib/python3.12/dist-packages (from lancedb->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 11)) (2.1.0)\n",
            "Requirement already satisfied: pyarrow>=16 in /usr/local/lib/python3.12/dist-packages (from lancedb->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 11)) (18.1.0)\n",
            "Collecting lance-namespace>=0.3.2 (from lancedb->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 11))\n",
            "  Downloading lance_namespace-0.4.5-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting llama-index-cli<0.6,>=0.5.0 (from llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_index_cli-0.5.3-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting llama-index-core<0.15.0,>=0.14.13 (from llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_index_core-0.14.13-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-index-llms-openai<0.7,>=0.6.0 (from llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_index_llms_openai-0.6.18-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting llama-index-readers-file<0.6,>=0.5.0 (from llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_index_readers_file-0.5.6-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting pylance (from llama-index-vector-stores-lancedb->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 13))\n",
            "  Downloading pylance-2.0.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting tantivy (from llama-index-vector-stores-lancedb->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 13))\n",
            "  Downloading tantivy-0.25.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (336 bytes)\n",
            "Collecting llama-index-llms-openai-like<0.7,>=0.5.0 (from llama-index-llms-openrouter->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 17))\n",
            "  Downloading llama_index_llms_openai_like-0.6.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 18)) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 18)) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 18)) (2025.11.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 20)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 20)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 20)) (2025.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 21)) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 21)) (0.13.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 21)) (1.3.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 22)) (10.8.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 22)) (0.60.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 22)) (0.12.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 22)) (2.9.0+cpu)\n",
            "Collecting triton>=2 (from openai-whisper->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 22))\n",
            "  Downloading triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 23)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 23)) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 23)) (0.4.2)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 24)) (5.0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 24)) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 24)) (1.16.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 26)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 26)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 26)) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 26)) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 26)) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 26)) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 26)) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 26)) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 26)) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 26)) (0.4.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (3.11)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi<1.0,>=0.115.2->gradio->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (0.0.4)\n",
            "Requirement already satisfied: pyparsing<4,>=3.1 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (0.16.0)\n",
            "\u001b[33mWARNING: huggingface-hub 1.3.7 does not provide the extra 'inference'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 10)) (0.8.5)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 9)) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 9)) (5.9.1)\n",
            "Collecting lance-namespace-urllib3-client==0.4.5 (from lance-namespace>=0.3.2->lancedb->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 11))\n",
            "  Downloading lance_namespace_urllib3_client-0.4.5-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: urllib3<3.0.0,>=1.25.3 in /usr/local/lib/python3.12/dist-packages (from lance-namespace-urllib3-client==0.4.5->lance-namespace>=0.3.2->lancedb->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 11)) (2.5.0)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.6 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12)) (3.13.3)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12)) (0.22.1)\n",
            "Collecting banks<3,>=2.2.0 (from llama-index-core<0.15.0,>=0.14.13->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading banks-2.4.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting dataclasses-json (from llama-index-core<0.15.0,>=0.14.13->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.13->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.15.0,>=0.14.13->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting filetype<2,>=1.2.0 (from llama-index-core<0.15.0,>=0.14.13->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting llama-index-workflows!=2.9.0,<3,>=2 (from llama-index-core<0.15.0,>=0.14.13->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_index_workflows-2.14.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12)) (3.6.1)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12)) (4.5.1)\n",
            "Collecting setuptools>=18.5 (from ipython->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 10))\n",
            "  Using cached setuptools-82.0.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.13->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12)) (2.0.46)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12)) (9.1.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.15.0,>=0.14.13->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12)) (2.1.0)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.13->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting llama-cloud==0.1.35 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud-0.1.35-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting wrapt (from llama-index-core<0.15.0,>=0.14.13->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12)) (0.7.1)\n",
            "Collecting pypdf<7,>=6.1.3 (from llama-index-readers-file<0.6,>=0.5.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading pypdf-6.7.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.6,>=0.5.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.92-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 10)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 10)) (0.5.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 4)) (0.6.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 20)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 2)) (3.4.4)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 26)) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 26)) (0.1.5)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 22)) (1.14.0)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 24)) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 24)) (0.7.0)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 26)) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 26)) (7.5.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 22)) (0.43.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 24)) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.13->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.13->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.13->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.13->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.13->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12)) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.13->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.13->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12)) (1.22.0)\n",
            "Collecting griffe (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.13->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading griffe-1.15.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15.0,>=0.14.13->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting llama-cloud-services>=0.6.92 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.92-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (4.0.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.13->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12)) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 22)) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.15.0,>=0.14.13->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.15.0,>=0.14.13->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "INFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.91-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.91 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.91-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.90-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.90 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.90-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.89-py3-none-any.whl.metadata (6.6 kB)\n",
            "INFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting llama-cloud-services>=0.6.89 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.89-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.88-py3-none-any.whl.metadata (6.6 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting llama-cloud-services>=0.6.88 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.88-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.87-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.87 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.87-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.86-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.86 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.86-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.85-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.85 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.85-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.84-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.84 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.84-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.83-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.82 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.83-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Downloading llama_cloud_services-0.6.82-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.82-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading llama_parse-0.6.81-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.81 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.81-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.80-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.80 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.80-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.79-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.79 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.79-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.78-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.78 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.78-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.77-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.77 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.77-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.76-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.76 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.76-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.75-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.75 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.75-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.74-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.74 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.74-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.73-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.73 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.73-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.72-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.72 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.72-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.71-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.71 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.71-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.70-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.70 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.70-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.69-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.69 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.69-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.68-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.68 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.68-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.67-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.67 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.67-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.66-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.66 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.66-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.65-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.64 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.65-py3-none-any.whl.metadata (3.3 kB)\n",
            "  Downloading llama_cloud_services-0.6.64-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.64-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading llama_parse-0.6.63-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.63 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.63-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.62-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.62 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.62-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.60-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.60 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.60-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.59-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.59 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.59-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.58-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.58 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.58-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.57-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.56 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.57-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading llama_cloud_services-0.6.56-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.56-py3-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading llama_parse-0.6.55-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.55 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.55-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_parse-0.6.54-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud-services>=0.6.54 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading llama_cloud_services-0.6.54-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv<2,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12)) (1.2.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 6)) (0.1.2)\n",
            "Collecting colorama>=0.4 (from griffe->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.13->llama-index->-r /content/drive/MyDrive/Outskill/rag_day7/assignments/requirements.txt (line 12))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Downloading lancedb-0.29.2-cp39-abi3-manylinux_2_28_x86_64.whl (47.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.2/47.2 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index-0.14.13-py3-none-any.whl (7.5 kB)\n",
            "Downloading llama_index_vector_stores_lancedb-0.4.4-py3-none-any.whl (8.0 kB)\n",
            "Downloading llama_index_embeddings_huggingface-0.6.1-py3-none-any.whl (8.9 kB)\n",
            "Downloading llama_index_llms_huggingface_api-0.6.2-py3-none-any.whl (7.5 kB)\n",
            "Downloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl (7.0 kB)\n",
            "Downloading llama_index_llms_openrouter-0.4.4-py3-none-any.whl (4.9 kB)\n",
            "Downloading yt_dlp-2026.2.4-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lance_namespace-0.4.5-py3-none-any.whl (11 kB)\n",
            "Downloading lance_namespace_urllib3_client-0.4.5-py3-none-any.whl (277 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m278.0/278.0 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_cli-0.5.3-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_core-0.14.13-py3-none-any.whl (11.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m104.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl (17 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading llama_cloud-0.1.35-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m303.3/303.3 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_llms_openai-0.6.18-py3-none-any.whl (26 kB)\n",
            "Downloading llama_index_llms_openai_like-0.6.0-py3-none-any.whl (4.9 kB)\n",
            "Downloading llama_index_readers_file-0.5.6-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl (3.2 kB)\n",
            "Using cached setuptools-82.0.0-py3-none-any.whl (1.0 MB)\n",
            "Downloading triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (188.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.3/188.3 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pylance-2.0.0-cp39-abi3-manylinux_2_28_x86_64.whl (57.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.6/57.6 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tantivy-0.25.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading banks-2.4.0-py3-none-any.whl (34 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading llama_index_workflows-2.14.1-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m96.8/96.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.6.54-py3-none-any.whl (4.9 kB)\n",
            "Downloading llama_cloud_services-0.6.54-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-6.7.0-py3-none-any.whl (330 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m330.6/330.6 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl (15 kB)\n",
            "Downloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading griffe-1.15.0-py3-none-any.whl (150 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803980 sha256=c3fa4e2088fc9286a124724979f59badafd35235faa2199349410c4aa7325440\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/d2/20/09ec9bef734d126cba375b15898010b6cc28578d8afdde5869\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: striprtf, filetype, dirtyjson, yt-dlp, wrapt, triton, tantivy, setuptools, pypdf, mypy-extensions, marshmallow, jedi, colorama, typing-inspect, griffe, deprecated, openai-whisper, llama-index-instrumentation, llama-cloud, lance-namespace-urllib3-client, dataclasses-json, banks, llama-index-workflows, lance-namespace, pylance, llama-index-core, lancedb, llama-index-vector-stores-lancedb, llama-index-readers-file, llama-index-llms-openai, llama-index-llms-huggingface-api, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-cloud-services, llama-parse, llama-index-llms-openai-like, llama-index-embeddings-huggingface, llama-index-cli, llama-index-readers-llama-parse, llama-index-llms-openrouter, llama-index\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 2.1.0\n",
            "    Uninstalling wrapt-2.1.0:\n",
            "      Successfully uninstalled wrapt-2.1.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "Successfully installed banks-2.4.0 colorama-0.4.6 dataclasses-json-0.6.7 deprecated-1.2.18 dirtyjson-1.0.8 filetype-1.2.0 griffe-1.15.0 jedi-0.19.2 lance-namespace-0.4.5 lance-namespace-urllib3-client-0.4.5 lancedb-0.29.2 llama-cloud-0.1.35 llama-cloud-services-0.6.54 llama-index-0.14.13 llama-index-cli-0.5.3 llama-index-core-0.14.13 llama-index-embeddings-huggingface-0.6.1 llama-index-embeddings-openai-0.5.1 llama-index-indices-managed-llama-cloud-0.9.4 llama-index-instrumentation-0.4.2 llama-index-llms-huggingface-api-0.6.2 llama-index-llms-openai-0.6.18 llama-index-llms-openai-like-0.6.0 llama-index-llms-openrouter-0.4.4 llama-index-readers-file-0.5.6 llama-index-readers-llama-parse-0.5.1 llama-index-vector-stores-lancedb-0.4.4 llama-index-workflows-2.14.1 llama-parse-0.6.54 marshmallow-3.26.2 mypy-extensions-1.1.0 openai-whisper-20250625 pylance-2.0.0 pypdf-6.7.0 setuptools-82.0.0 striprtf-0.0.26 tantivy-0.25.1 triton-3.6.0 typing-inspect-0.9.0 wrapt-1.17.3 yt-dlp-2026.2.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack"
                ]
              },
              "id": "29f54aa1247b4fbb81ff3bf3db4ad3f4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENROUTER_API_KEY\"] = userdata.get('OPENROUTER_API_KEY')"
      ],
      "metadata": {
        "id": "HIcDQwiNSF5g"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bouPQATASCV5",
        "outputId": "c52063f0-ec5e-4b69-cb46-438c6ccacdd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… All libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import all required libraries\n",
        "import gradio as gr\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Any\n",
        "\n",
        "# LlamaIndex core components\n",
        "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext, Settings\n",
        "from llama_index.vector_stores.lancedb import LanceDBVectorStore\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.llms.openrouter import OpenRouter\n",
        "\n",
        "# Advanced RAG components\n",
        "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
        "from llama_index.core.response_synthesizers import TreeSummarize, Refine, CompactAndRefine\n",
        "from llama_index.core.retrievers import VectorIndexRetriever\n",
        "\n",
        "print(\"âœ… All libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZ7V3ccZSCV5"
      },
      "source": [
        "## ðŸ¤– Part 2: Advanced RAG Backend Class\n",
        "\n",
        "Create an advanced RAG backend that supports dynamic configuration of all parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "6cf68781c6bc4252881431571fe96c64",
            "20d43823636d4dd798385827df1193b8",
            "16158ece7efb441db020ca6433312b29",
            "f4f45b4b00444c0d839c9fb1b7645bd3",
            "679b5a5cca6c42ea97fb1a16ebe2fc13",
            "f547e6891cb24f2e984b1a9c2272c436",
            "4fa0cf2b3e8e44ce94c2cd9741cd0585",
            "0ad169e0d0414ae5b5bf19cc913885e3",
            "1af23fbe0b8b40e6a3715f9975ebd21c",
            "d676fa1fa6f648a081ac40ccc1f9baf1",
            "2e7dc2d27ff04952b34de83d4fe6b178"
          ]
        },
        "id": "1Moc3ggwSCV6",
        "outputId": "03736c0b-8d07-40e3-b6eb-32a18a462d25"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cf68781c6bc4252881431571fe96c64"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertModel LOAD REPORT from: BAAI/bge-small-en-v1.5\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Advanced RAG Backend initialized and ready!\n"
          ]
        }
      ],
      "source": [
        "class AdvancedRAGBackend:\n",
        "    \"\"\"Advanced RAG backend with configurable parameters.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.index = None\n",
        "        self.available_models = [\"gpt-4o\", \"gpt-4o-mini\"]\n",
        "        self.available_postprocessors = [\"SimilarityPostprocessor\"]\n",
        "        self.available_synthesizers = [\"TreeSummarize\", \"Refine\", \"CompactAndRefine\", \"Default\"]\n",
        "        self.update_settings()\n",
        "\n",
        "    def update_settings(self, model: str = \"gpt-4o-mini\", temperature: float = 0.1, chunk_size: int = 512, chunk_overlap: int = 50):\n",
        "        \"\"\"Update LlamaIndex settings based on user configuration.\"\"\"\n",
        "        # Set up the LLM using OpenRouter\n",
        "        api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "        if api_key:\n",
        "            Settings.llm = OpenRouter(\n",
        "                api_key=api_key,\n",
        "                model=model,\n",
        "                temperature=temperature\n",
        "            )\n",
        "\n",
        "        # Set up the embedding model (keep this constant)\n",
        "        Settings.embed_model = HuggingFaceEmbedding(\n",
        "            model_name=\"BAAI/bge-small-en-v1.5\",\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "\n",
        "        # Set chunking parameters from function parameters\n",
        "        Settings.chunk_size = chunk_size\n",
        "        Settings.chunk_overlap = chunk_overlap\n",
        "\n",
        "    def initialize_database(self, data_folder=\"../data\"):\n",
        "        \"\"\"Initialize the vector database with documents.\"\"\"\n",
        "        # Check if data folder exists\n",
        "        if not Path(data_folder).exists():\n",
        "            return f\"âŒ Data folder '{data_folder}' not found!\"\n",
        "\n",
        "        try:\n",
        "            # Create vector store\n",
        "            vector_store = LanceDBVectorStore(\n",
        "                uri=\"./advanced_rag_vectordb\",\n",
        "                table_name=\"documents\"\n",
        "            )\n",
        "\n",
        "            # Load documents\n",
        "            reader = SimpleDirectoryReader(input_dir=data_folder, recursive=True)\n",
        "            documents = reader.load_data()\n",
        "\n",
        "            # Create storage context and index\n",
        "            storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "            self.index = VectorStoreIndex.from_documents(\n",
        "                documents,\n",
        "                storage_context=storage_context,\n",
        "                show_progress=True\n",
        "            )\n",
        "\n",
        "            return f\"âœ… Database initialized successfully with {len(documents)} documents!\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"âŒ Error initializing database: {str(e)}\"\n",
        "\n",
        "    def get_postprocessor(self, postprocessor_name: str, similarity_cutoff: float):\n",
        "        \"\"\"Get the selected postprocessor.\"\"\"\n",
        "        if postprocessor_name == \"SimilarityPostprocessor\":\n",
        "            return SimilarityPostprocessor(similarity_cutoff=similarity_cutoff)\n",
        "        elif postprocessor_name == \"None\":\n",
        "            return None\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def get_synthesizer(self, synthesizer_name: str):\n",
        "        \"\"\"Get the selected response synthesizer.\"\"\"\n",
        "        if synthesizer_name == \"TreeSummarize\":\n",
        "            return TreeSummarize()\n",
        "        elif synthesizer_name == \"Refine\":\n",
        "            return Refine()\n",
        "        elif synthesizer_name == \"CompactAndRefine\":\n",
        "            return CompactAndRefine()\n",
        "        elif synthesizer_name == \"Default\":\n",
        "            return None\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def advanced_query(self, question: str, model: str, temperature: float,\n",
        "                      chunk_size: int, chunk_overlap: int, similarity_top_k: int,\n",
        "                      postprocessor_names: List[str], similarity_cutoff: float,\n",
        "                      synthesizer_name: str) -> Dict[str, Any]:\n",
        "        \"\"\"Query the RAG system with advanced configuration.\"\"\"\n",
        "\n",
        "        # Check if index exists\n",
        "        if self.index is None:\n",
        "            return {\"response\": \"âŒ Please initialize the database first!\", \"sources\": [], \"config\": {}}\n",
        "\n",
        "        # Check if question is empty\n",
        "        if not question or not question.strip():\n",
        "            return {\"response\": \"âš ï¸ Please enter a question first!\", \"sources\": [], \"config\": {}}\n",
        "\n",
        "        try:\n",
        "            # Update settings with new parameters\n",
        "            self.update_settings(model, temperature, chunk_size, chunk_overlap)\n",
        "\n",
        "            # Get postprocessors\n",
        "            postprocessors = []\n",
        "            for name in postprocessor_names:\n",
        "                processor = self.get_postprocessor(name, similarity_cutoff)\n",
        "                if processor is not None:\n",
        "                    postprocessors.append(processor)\n",
        "\n",
        "            # Get synthesizer\n",
        "            synthesizer = self.get_synthesizer(synthesizer_name)\n",
        "\n",
        "            # Create query engine with all parameters\n",
        "            query_engine_kwargs = {\"similarity_top_k\": similarity_top_k}\n",
        "            if postprocessors:\n",
        "                query_engine_kwargs[\"node_postprocessors\"] = postprocessors\n",
        "            if synthesizer is not None:\n",
        "                query_engine_kwargs[\"response_synthesizer\"] = synthesizer\n",
        "\n",
        "            query_engine = self.index.as_query_engine(**query_engine_kwargs)\n",
        "\n",
        "            # Query and get response\n",
        "            response = query_engine.query(question)\n",
        "\n",
        "            # Extract source information if available\n",
        "            sources = []\n",
        "            if hasattr(response, 'source_nodes'):\n",
        "                for node in response.source_nodes:\n",
        "                    sources.append({\n",
        "                        \"text\": node.text[:200] + \"...\",\n",
        "                        \"score\": getattr(node, 'score', 0.0),\n",
        "                        \"source\": getattr(node.node, 'metadata', {}).get('file_name', 'Unknown')\n",
        "                    })\n",
        "\n",
        "            return {\n",
        "                \"response\": str(response),\n",
        "                \"sources\": sources,\n",
        "                \"config\": {\n",
        "                    \"model\": model,\n",
        "                    \"temperature\": temperature,\n",
        "                    \"chunk_size\": chunk_size,\n",
        "                    \"chunk_overlap\": chunk_overlap,\n",
        "                    \"similarity_top_k\": similarity_top_k,\n",
        "                    \"postprocessors\": postprocessor_names,\n",
        "                    \"similarity_cutoff\": similarity_cutoff,\n",
        "                    \"synthesizer\": synthesizer_name\n",
        "                }\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {\"response\": f\"âŒ Error processing query: {str(e)}\", \"sources\": [], \"config\": {}}\n",
        "\n",
        "# Initialize the backend\n",
        "rag_backend = AdvancedRAGBackend()\n",
        "print(\"ðŸš€ Advanced RAG Backend initialized and ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7oQyXGjSCV6"
      },
      "source": [
        "## ðŸŽ¨ Part 3: Advanced Gradio Interface\n",
        "\n",
        "Create a sophisticated Gradio interface with all the configuration options specified:\n",
        "1. Database initialization button\n",
        "2. Search query input and button  \n",
        "3. Model selection dropdown\n",
        "4. Temperature slider\n",
        "5. Chunk size and overlap inputs\n",
        "6. Similarity top-k slider\n",
        "7. Node postprocessor multiselect\n",
        "8. Similarity cutoff slider\n",
        "9. Response synthesizer multiselect\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_advanced_rag_interface():\n",
        "    \"\"\"Create advanced RAG interface with full configuration options.\"\"\"\n",
        "\n",
        "    def initialize_db():\n",
        "        \"\"\"Handle database initialization.\"\"\"\n",
        "        return rag_backend.initialize_database(data_folder=\"/content/drive/MyDrive/Outskill/rag_day6/session_2/data\")\n",
        "\n",
        "    def handle_advanced_query(question, model, temperature, chunk_size, chunk_overlap,\n",
        "                             similarity_top_k, postprocessors, similarity_cutoff, synthesizer):\n",
        "        \"\"\"Handle advanced RAG queries with all configuration options.\"\"\"\n",
        "        result = rag_backend.advanced_query(\n",
        "            question, model, temperature, chunk_size, chunk_overlap,\n",
        "            similarity_top_k, postprocessors, similarity_cutoff, synthesizer\n",
        "        )\n",
        "\n",
        "        # Format configuration for display\n",
        "        config_text = f\"\"\"**ðŸ“Š Current Configuration:**\n",
        "\n",
        "ðŸ¤– **Model Settings:**\n",
        "  â€¢ Model: {result['config'].get('model', 'N/A')}\n",
        "  â€¢ Temperature: {result['config'].get('temperature', 'N/A')}\n",
        "\n",
        "ðŸ“ **Chunking Parameters:**\n",
        "  â€¢ Chunk Size: {result['config'].get('chunk_size', 'N/A')}\n",
        "  â€¢ Chunk Overlap: {result['config'].get('chunk_overlap', 'N/A')}\n",
        "\n",
        "ðŸ” **Retrieval Settings:**\n",
        "  â€¢ Similarity Top-K: {result['config'].get('similarity_top_k', 'N/A')}\n",
        "  â€¢ Similarity Cutoff: {result['config'].get('similarity_cutoff', 'N/A')}\n",
        "\n",
        "âš™ï¸ **Advanced Options:**\n",
        "  â€¢ Postprocessors: {', '.join(result['config'].get('postprocessors', [])) or 'None'}\n",
        "  â€¢ Synthesizer: {result['config'].get('synthesizer', 'N/A')}\"\"\"\n",
        "\n",
        "        return result[\"response\"], config_text\n",
        "\n",
        "    # Create beautiful custom theme\n",
        "    custom_theme = gr.themes.Soft(\n",
        "        primary_hue=\"blue\",\n",
        "        secondary_hue=\"cyan\",\n",
        "        neutral_hue=\"slate\",\n",
        "        font=[gr.themes.GoogleFont(\"Inter\"), \"ui-sans-serif\", \"system-ui\", \"sans-serif\"],\n",
        "    ).set(\n",
        "        body_background_fill=\"*neutral_50\",\n",
        "        body_background_fill_dark=\"*neutral_900\",\n",
        "        button_primary_background_fill=\"*primary_600\",\n",
        "        button_primary_background_fill_hover=\"*primary_700\",\n",
        "        button_primary_text_color=\"white\",\n",
        "        slider_color=\"*primary_600\",\n",
        "        block_title_text_weight=\"600\",\n",
        "        block_border_width=\"2px\",\n",
        "        block_shadow=\"*shadow_drop_lg\",\n",
        "    )\n",
        "\n",
        "    with gr.Blocks(theme=custom_theme, title=\"ðŸš€ Advanced RAG Assistant\", css=\"\"\"\n",
        "        .gradio-container {\n",
        "            max-width: 1400px !important;\n",
        "        }\n",
        "        .config-panel {\n",
        "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "            padding: 20px;\n",
        "            border-radius: 10px;\n",
        "            color: white;\n",
        "        }\n",
        "        h1 {\n",
        "            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
        "            -webkit-background-clip: text;\n",
        "            -webkit-text-fill-color: transparent;\n",
        "            font-size: 2.5em !important;\n",
        "            font-weight: 800 !important;\n",
        "            margin-bottom: 0.5em !important;\n",
        "        }\n",
        "        .description {\n",
        "            font-size: 1.1em;\n",
        "            color: #64748b;\n",
        "            margin-bottom: 2em;\n",
        "        }\n",
        "        .parameter-group {\n",
        "            background: #f8fafc;\n",
        "            padding: 15px;\n",
        "            border-radius: 8px;\n",
        "            margin-bottom: 15px;\n",
        "            border-left: 4px solid #667eea;\n",
        "        }\n",
        "    \"\"\") as interface:\n",
        "\n",
        "        # Header section\n",
        "        gr.Markdown(\n",
        "            \"\"\"\n",
        "            # ðŸš€ Advanced RAG Assistant\n",
        "            ### Configurable Retrieval-Augmented Generation System\n",
        "\n",
        "            <div class=\"description\">\n",
        "            Welcome to the Advanced RAG Assistant! This powerful tool allows you to query your documents with full control over\n",
        "            every aspect of the retrieval and generation process. Configure models, chunking strategies, retrieval parameters,\n",
        "            and response synthesis to get the perfect results for your use case.\n",
        "            </div>\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "        # Database initialization section\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                gr.Markdown(\"### ðŸ—„ï¸ Database Initialization\")\n",
        "                init_btn = gr.Button(\n",
        "                    \"ðŸš€ Initialize Vector Database\",\n",
        "                    variant=\"primary\",\n",
        "                    size=\"lg\",\n",
        "                    scale=1\n",
        "                )\n",
        "                status_output = gr.Textbox(\n",
        "                    label=\"Initialization Status\",\n",
        "                    placeholder=\"Click the button above to initialize the database...\",\n",
        "                    lines=2,\n",
        "                    interactive=False\n",
        "                )\n",
        "\n",
        "        gr.Markdown(\"---\")\n",
        "\n",
        "        # Main layout with configuration and query interface\n",
        "        with gr.Row():\n",
        "            # Left column - Configuration panel\n",
        "            with gr.Column(scale=1):\n",
        "                gr.Markdown(\"### âš™ï¸ RAG Configuration\")\n",
        "\n",
        "                # Model Settings Group\n",
        "                with gr.Group():\n",
        "                    gr.Markdown(\"#### ðŸ¤– Model Settings\")\n",
        "                    model_dropdown = gr.Dropdown(\n",
        "                        choices=[\"gpt-4o\", \"gpt-4o-mini\"],\n",
        "                        value=\"gpt-4o-mini\",\n",
        "                        label=\"Model Selection\",\n",
        "                        info=\"Choose the LLM model for response generation\"\n",
        "                    )\n",
        "\n",
        "                    temperature_slider = gr.Slider(\n",
        "                        minimum=0.0,\n",
        "                        maximum=1.0,\n",
        "                        step=0.1,\n",
        "                        value=0.1,\n",
        "                        label=\"Temperature\",\n",
        "                        info=\"Lower = more focused, Higher = more creative\"\n",
        "                    )\n",
        "\n",
        "                # Chunking Parameters Group\n",
        "                with gr.Group():\n",
        "                    gr.Markdown(\"#### ðŸ“ Chunking Parameters\")\n",
        "                    chunk_size_input = gr.Number(\n",
        "                        value=512,\n",
        "                        label=\"Chunk Size\",\n",
        "                        info=\"Number of tokens per chunk (256-1024 recommended)\",\n",
        "                        minimum=128,\n",
        "                        maximum=2048\n",
        "                    )\n",
        "\n",
        "                    chunk_overlap_input = gr.Number(\n",
        "                        value=50,\n",
        "                        label=\"Chunk Overlap\",\n",
        "                        info=\"Overlap between chunks to maintain context\",\n",
        "                        minimum=0,\n",
        "                        maximum=200\n",
        "                    )\n",
        "\n",
        "                # Retrieval Parameters Group\n",
        "                with gr.Group():\n",
        "                    gr.Markdown(\"#### ðŸ” Retrieval Parameters\")\n",
        "                    similarity_topk_slider = gr.Slider(\n",
        "                        minimum=1,\n",
        "                        maximum=20,\n",
        "                        step=1,\n",
        "                        value=5,\n",
        "                        label=\"Similarity Top-K\",\n",
        "                        info=\"Number of most similar chunks to retrieve\"\n",
        "                    )\n",
        "\n",
        "                    similarity_cutoff_slider = gr.Slider(\n",
        "                        minimum=0.0,\n",
        "                        maximum=1.0,\n",
        "                        step=0.1,\n",
        "                        value=0.3,\n",
        "                        label=\"Similarity Cutoff\",\n",
        "                        info=\"Minimum similarity score threshold\"\n",
        "                    )\n",
        "\n",
        "                # Advanced Options Group\n",
        "                with gr.Group():\n",
        "                    gr.Markdown(\"#### ðŸŽ¯ Advanced Options\")\n",
        "                    postprocessor_checkbox = gr.CheckboxGroup(\n",
        "                        choices=[\"SimilarityPostprocessor\"],\n",
        "                        value=[\"SimilarityPostprocessor\"],\n",
        "                        label=\"Node Postprocessors\",\n",
        "                        info=\"Select postprocessing filters\"\n",
        "                    )\n",
        "\n",
        "                    synthesizer_dropdown = gr.Dropdown(\n",
        "                        choices=[\"Default\", \"TreeSummarize\", \"Refine\", \"CompactAndRefine\"],\n",
        "                        value=\"Default\",\n",
        "                        label=\"Response Synthesizer\",\n",
        "                        info=\"Choose how to combine retrieved information\"\n",
        "                    )\n",
        "\n",
        "            # Right column - Query interface\n",
        "            with gr.Column(scale=2):\n",
        "                gr.Markdown(\"### ðŸ’¬ Query Interface\")\n",
        "\n",
        "                query_input = gr.Textbox(\n",
        "                    label=\"Ask a Question\",\n",
        "                    placeholder=\"Enter your question here... (e.g., 'What are the main themes discussed in the documents?')\",\n",
        "                    lines=3,\n",
        "                    max_lines=5\n",
        "                )\n",
        "\n",
        "                submit_btn = gr.Button(\n",
        "                    \"ðŸ” Ask Question\",\n",
        "                    variant=\"primary\",\n",
        "                    size=\"lg\"\n",
        "                )\n",
        "\n",
        "                gr.Markdown(\"#### ðŸ“„ Response\")\n",
        "                response_output = gr.Textbox(\n",
        "                    label=\"Answer\",\n",
        "                    placeholder=\"The AI response will appear here...\",\n",
        "                    lines=12,\n",
        "                    max_lines=20,\n",
        "                    interactive=False,\n",
        "                    show_copy_button=True\n",
        "                )\n",
        "\n",
        "                gr.Markdown(\"#### ðŸ“Š Configuration Used\")\n",
        "                config_display = gr.Markdown(\n",
        "                    value=\"*Configuration details will appear here after running a query...*\"\n",
        "                )\n",
        "\n",
        "        # Add helpful examples\n",
        "        gr.Markdown(\"---\")\n",
        "        gr.Markdown(\n",
        "            \"\"\"\n",
        "            ### ðŸ’¡ Quick Tips\n",
        "\n",
        "            **Getting Started:**\n",
        "            1. Click \"Initialize Vector Database\" first\n",
        "            2. Configure your RAG parameters in the left panel\n",
        "            3. Enter your question and click \"Ask Question\"\n",
        "\n",
        "            **Optimization Tips:**\n",
        "            - **For precise factual queries:** Use low temperature (0.1-0.3) with gpt-4o\n",
        "            - **For creative responses:** Increase temperature (0.7-0.9) and use TreeSummarize\n",
        "            - **For large documents:** Increase chunk size to 1024 and top-k to 10-15\n",
        "            - **For focused answers:** Use smaller chunk size (256) and lower top-k (3-5)\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "        # Example queries\n",
        "        gr.Examples(\n",
        "            examples=[\n",
        "                [\"What are the main topics covered in the documents?\"],\n",
        "                [\"Summarize the key findings and conclusions.\"],\n",
        "                [\"What are the most important technical details mentioned?\"],\n",
        "                [\"How do the different sections relate to each other?\"],\n",
        "            ],\n",
        "            inputs=query_input,\n",
        "            label=\"ðŸ“ Example Questions\"\n",
        "        )\n",
        "\n",
        "        # Connect functions to components\n",
        "        init_btn.click(\n",
        "            initialize_db,\n",
        "            outputs=[status_output]\n",
        "        )\n",
        "\n",
        "        submit_btn.click(\n",
        "            handle_advanced_query,\n",
        "            inputs=[\n",
        "                query_input, model_dropdown, temperature_slider,\n",
        "                chunk_size_input, chunk_overlap_input, similarity_topk_slider,\n",
        "                postprocessor_checkbox, similarity_cutoff_slider, synthesizer_dropdown\n",
        "            ],\n",
        "            outputs=[response_output, config_display]\n",
        "        )\n",
        "\n",
        "        # Also allow pressing Enter to submit\n",
        "        query_input.submit(\n",
        "            handle_advanced_query,\n",
        "            inputs=[\n",
        "                query_input, model_dropdown, temperature_slider,\n",
        "                chunk_size_input, chunk_overlap_input, similarity_topk_slider,\n",
        "                postprocessor_checkbox, similarity_cutoff_slider, synthesizer_dropdown\n",
        "            ],\n",
        "            outputs=[response_output, config_display]\n",
        "        )\n",
        "\n",
        "    return interface\n",
        "\n",
        "# Create the interface\n",
        "advanced_interface = create_advanced_rag_interface()\n",
        "print(\"âœ… Advanced RAG interface created successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUEVPCmFXdlB",
        "outputId": "e3e72b2a-99df-4b25-e586-38d32618bbf6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1440944217.py:55: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=custom_theme, title=\"ðŸš€ Advanced RAG Assistant\", css=\"\"\"\n",
            "/tmp/ipython-input-1440944217.py:55: DeprecationWarning: The 'css' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'css' to Blocks.launch() instead.\n",
            "  with gr.Blocks(theme=custom_theme, title=\"ðŸš€ Advanced RAG Assistant\", css=\"\"\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Advanced RAG interface created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNoR-nkYSCV7"
      },
      "source": [
        "## ðŸš€ Part 4: Launch Your Advanced Application\n",
        "\n",
        "Launch your advanced Gradio application and test all the configuration options!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0XZfYC6OSCV7",
        "outputId": "408c7e05-6a40-4f7a-edef-2586b5a3b44b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ‰ Launching your Advanced RAG Assistant...\n",
            "ðŸ”— Your application will open in a new browser tab!\n",
            "\n",
            "âš ï¸  Make sure your OPENROUTER_API_KEY environment variable is set!\n",
            "\n",
            "ðŸ“‹ Testing Instructions:\n",
            "1. Click 'Initialize Vector Database' button first\n",
            "2. Wait for success message\n",
            "3. Configure your RAG parameters:\n",
            "   - Choose model (gpt-4o, gpt-4o-mini)\n",
            "   - Adjust temperature (0.0 = deterministic, 1.0 = creative)\n",
            "   - Set chunk size and overlap\n",
            "   - Choose similarity top-k\n",
            "   - Select postprocessors and synthesizer\n",
            "4. Enter a question and click 'Ask Question'\n",
            "5. Review both the response and configuration used\n",
            "\n",
            "ðŸ§ª Experiments to try:\n",
            "- Compare different models with the same question\n",
            "- Test temperature effects (0.1 vs 0.9)\n",
            "- Try different chunk sizes (256 vs 1024)\n",
            "- Compare synthesizers (TreeSummarize vs Refine)\n",
            "- Adjust similarity cutoff to filter results\n",
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c9cd041e1d90d63705.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c9cd041e1d90d63705.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "print(\"ðŸŽ‰ Launching your Advanced RAG Assistant...\")\n",
        "print(\"ðŸ”— Your application will open in a new browser tab!\")\n",
        "print(\"\")\n",
        "print(\"âš ï¸  Make sure your OPENROUTER_API_KEY environment variable is set!\")\n",
        "print(\"\")\n",
        "print(\"ðŸ“‹ Testing Instructions:\")\n",
        "print(\"1. Click 'Initialize Vector Database' button first\")\n",
        "print(\"2. Wait for success message\")\n",
        "print(\"3. Configure your RAG parameters:\")\n",
        "print(\"   - Choose model (gpt-4o, gpt-4o-mini)\")\n",
        "print(\"   - Adjust temperature (0.0 = deterministic, 1.0 = creative)\")\n",
        "print(\"   - Set chunk size and overlap\")\n",
        "print(\"   - Choose similarity top-k\")\n",
        "print(\"   - Select postprocessors and synthesizer\")\n",
        "print(\"4. Enter a question and click 'Ask Question'\")\n",
        "print(\"5. Review both the response and configuration used\")\n",
        "print(\"\")\n",
        "print(\"ðŸ§ª Experiments to try:\")\n",
        "print(\"- Compare different models with the same question\")\n",
        "print(\"- Test temperature effects (0.1 vs 0.9)\")\n",
        "print(\"- Try different chunk sizes (256 vs 1024)\")\n",
        "print(\"- Compare synthesizers (TreeSummarize vs Refine)\")\n",
        "print(\"- Adjust similarity cutoff to filter results\")\n",
        "\n",
        "# Your code here:\n",
        "advanced_interface.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CPZbvh4SCV7"
      },
      "source": [
        "## ðŸ’¡ Understanding the Configuration Options\n",
        "\n",
        "### Model Selection\n",
        "- **gpt-4o**: Latest and most capable model, best quality responses\n",
        "- **gpt-4o-mini**: Faster and cheaper while maintaining good quality\n",
        "\n",
        "### Temperature (0.0 - 1.0)\n",
        "- **0.0-0.3**: Deterministic, factual responses\n",
        "- **0.4-0.7**: Balanced creativity and accuracy\n",
        "- **0.8-1.0**: More creative and varied responses\n",
        "\n",
        "### Chunk Size & Overlap\n",
        "- **Chunk Size**: How much text to process at once (256-1024 typical)\n",
        "- **Chunk Overlap**: Overlap between chunks to maintain context (10-100 typical)\n",
        "\n",
        "### Similarity Top-K (1-20)\n",
        "- **Lower values (3-5)**: More focused, faster responses\n",
        "- **Higher values (8-15)**: More comprehensive, detailed responses\n",
        "\n",
        "### Node Postprocessors\n",
        "- **SimilarityPostprocessor**: Filters out low-relevance documents\n",
        "\n",
        "### Similarity Cutoff (0.0-1.0)\n",
        "- **0.1-0.3**: More permissive, includes potentially relevant docs\n",
        "- **0.5-0.8**: More strict, only highly relevant docs\n",
        "\n",
        "### Response Synthesizers\n",
        "- **TreeSummarize**: Hierarchical summarization, good for complex topics\n",
        "- **Refine**: Iterative refinement, builds detailed responses\n",
        "- **CompactAndRefine**: Efficient version of Refine\n",
        "- **Default**: Standard synthesis approach\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyPGQdlmSCV8"
      },
      "source": [
        "## âœ… Assignment Completion Checklist\n",
        "\n",
        "Before submitting, ensure you have:\n",
        "\n",
        "- [ ] Set up your OPENROUTER_API_KEY environment variable\n",
        "- [ ] Imported all necessary libraries including advanced RAG components\n",
        "- [ ] Created AdvancedRAGBackend class with configurable parameters\n",
        "- [ ] Implemented all required methods:\n",
        "  - [ ] `update_settings()` - Updates LLM and chunking parameters\n",
        "  - [ ] `initialize_database()` - Sets up vector database\n",
        "  - [ ] `get_postprocessor()` - Returns selected postprocessor\n",
        "  - [ ] `get_synthesizer()` - Returns selected synthesizer\n",
        "  - [ ] `advanced_query()` - Handles queries with all configuration options\n",
        "- [ ] Created advanced Gradio interface with all required components:\n",
        "  - [ ] Initialize database button\n",
        "  - [ ] Model selection dropdown (gpt-4o, gpt-4o-mini)\n",
        "  - [ ] Temperature slider (0 to 1, step 0.1)\n",
        "  - [ ] Chunk size input (default 512)\n",
        "  - [ ] Chunk overlap input (default 50)\n",
        "  - [ ] Similarity top-k slider (1 to 20, default 5)\n",
        "  - [ ] Node postprocessor multiselect\n",
        "  - [ ] Similarity cutoff slider (0.0 to 1.0, step 0.1, default 0.3)\n",
        "  - [ ] Response synthesizer dropdown\n",
        "  - [ ] Query input and submit button\n",
        "  - [ ] Response output\n",
        "  - [ ] Configuration display\n",
        "- [ ] Connected all components to backend functions\n",
        "- [ ] Successfully launched the application\n",
        "- [ ] Tested different parameter combinations\n",
        "- [ ] Verified all configuration options work correctly\n",
        "\n",
        "## ðŸŽŠ Congratulations!\n",
        "\n",
        "You've successfully built a professional, production-ready RAG application! You now have:\n",
        "\n",
        "- **Advanced Parameter Control**: Full control over all RAG system parameters\n",
        "- **Professional UI**: Clean, organized interface with proper layout\n",
        "- **Real-time Configuration**: Ability to experiment with different settings\n",
        "- **Production Patterns**: Understanding of how to build scalable AI applications\n",
        "\n",
        "## ðŸš€ Next Steps & Extensions\n",
        "\n",
        "**Potential Enhancements:**\n",
        "1. **Authentication**: Add user login and session management\n",
        "2. **Document Upload**: Allow users to upload their own documents\n",
        "3. **Chat History**: Implement conversation memory\n",
        "4. **Performance Monitoring**: Add response time and quality metrics\n",
        "5. **A/B Testing**: Compare different configurations side-by-side\n",
        "6. **Export Features**: Download responses and configurations\n",
        "7. **Advanced Visualizations**: Show document similarity scores and retrieval paths\n",
        "\n",
        "**Deployment Options:**\n",
        "- **Local**: Run on your machine for development\n",
        "- **Gradio Cloud**: Deploy with `interface.launch(share=True)`\n",
        "- **Hugging Face Spaces**: Deploy to Hugging Face for public access\n",
        "- **Docker**: Containerize for scalable deployment\n",
        "- **Cloud Platforms**: Deploy to AWS, GCP, or Azure\n",
        "\n",
        "You're now ready to build sophisticated AI-powered applications!\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OK4OGG_kYDMh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "accelerator",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6cf68781c6bc4252881431571fe96c64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20d43823636d4dd798385827df1193b8",
              "IPY_MODEL_16158ece7efb441db020ca6433312b29",
              "IPY_MODEL_f4f45b4b00444c0d839c9fb1b7645bd3"
            ],
            "layout": "IPY_MODEL_679b5a5cca6c42ea97fb1a16ebe2fc13"
          }
        },
        "20d43823636d4dd798385827df1193b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f547e6891cb24f2e984b1a9c2272c436",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4fa0cf2b3e8e44ce94c2cd9741cd0585",
            "value": "Loadingâ€‡weights:â€‡100%"
          }
        },
        "16158ece7efb441db020ca6433312b29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ad169e0d0414ae5b5bf19cc913885e3",
            "max": 199,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1af23fbe0b8b40e6a3715f9975ebd21c",
            "value": 199
          }
        },
        "f4f45b4b00444c0d839c9fb1b7645bd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d676fa1fa6f648a081ac40ccc1f9baf1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2e7dc2d27ff04952b34de83d4fe6b178",
            "value": "â€‡199/199â€‡[00:00&lt;00:00,â€‡502.93it/s,â€‡Materializingâ€‡param=pooler.dense.weight]"
          }
        },
        "679b5a5cca6c42ea97fb1a16ebe2fc13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f547e6891cb24f2e984b1a9c2272c436": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fa0cf2b3e8e44ce94c2cd9741cd0585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ad169e0d0414ae5b5bf19cc913885e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1af23fbe0b8b40e6a3715f9975ebd21c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d676fa1fa6f648a081ac40ccc1f9baf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e7dc2d27ff04952b34de83d4fe6b178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}